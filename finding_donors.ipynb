{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "## Project: Finding Donors for *CharityML*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a `'TODO'` statement. Please be sure to read the instructions carefully!\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.  \n",
    "\n",
    ">**Note:** Please specify WHICH VERSION OF PYTHON you are using when submitting this notebook. Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "In this project, you will employ several supervised algorithms of your choice to accurately model individuals' income using data collected from the 1994 U.S. Census. You will then choose the best candidate algorithm from preliminary results and further optimize this algorithm to best model the data. Your goal with this implementation is to construct a model that accurately predicts whether an individual makes more than $50,000. This sort of task can arise in a non-profit setting, where organizations survive on donations.  Understanding an individual's income can help a non-profit better understand how large of a donation to request, or whether or not they should reach out to begin with.  While it can be difficult to determine an individual's general income bracket directly from public sources, we can (as we will see) infer this value from other publically available features. \n",
    "\n",
    "The dataset for this project originates from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income). The datset was donated by Ron Kohavi and Barry Becker, after being published in the article _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. You can find the article by Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf). The data we investigate here consists of small changes to the original dataset, such as removing the `'fnlwgt'` feature and records with missing or ill-formatted entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exploring the Data\n",
    "Run the code cell below to load necessary Python libraries and load the census data. Note that the last column from this dataset, `'income'`, will be our target label (whether an individual makes more than, or at most, $50,000 annually). All other columns are features about each individual in the census database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass education_level  education-num  marital-status  \\\n",
       "0   39   State-gov       Bachelors           13.0   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male        2174.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country income  \n",
       "0            40.0   United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Census dataset\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# Success - Display the first record\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Data Exploration\n",
    "A cursory investigation of the dataset will determine how many individuals fit into either group, and will tell us about the percentage of these individuals making more than \\$50,000. In the code cell below, you will need to compute the following:\n",
    "- The total number of records, `'n_records'`\n",
    "- The number of individuals making more than \\$50,000 annually, `'n_greater_50k'`.\n",
    "- The number of individuals making at most \\$50,000 annually, `'n_at_most_50k'`.\n",
    "- The percentage of individuals making more than \\$50,000 annually, `'greater_percent'`.\n",
    "\n",
    "** HINT: ** You may need to look at the table above to understand how the `'income'` entries are formatted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78439697492371%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Total number of records\n",
    "n_records = len(data)\n",
    "\n",
    "# TODO: Number of records where individual's income is more than $50,000\n",
    "n_greater_50k = np.sum(data['income']=='>50K')\n",
    "\n",
    "# TODO: Number of records where individual's income is at most $50,000\n",
    "n_at_most_50k = np.sum(data['income']=='<=50K')\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "greater_percent = (n_greater_50k / n_records)*100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Featureset Exploration **\n",
    "\n",
    "* **age**: continuous. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: continuous. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **sex**: Female, Male. \n",
    "* **capital-gain**: continuous. \n",
    "* **capital-loss**: continuous. \n",
    "* **hours-per-week**: continuous. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparing the Data\n",
    "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured â€” this is typically known as **preprocessing**. Fortunately, for this dataset, there are no invalid or missing entries we must deal with, however, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Skewed Continuous Features\n",
    "A dataset may sometimes contain at least one feature whose values tend to lie near a single number, but will also have a non-trivial number of vastly larger or smaller values than that single number.  Algorithms can be sensitive to such distributions of values and can underperform if the range is not properly normalized. With the census dataset two features fit this description: '`capital-gain'` and `'capital-loss'`. \n",
    "\n",
    "Run the code cell below to plot a histogram of these two features. Note the range of the values present and how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XmYLFV9//H3h1VERVRABBQlxiXGBRAxGgQXRFyIW4IRubgbNdGoP8UVxF0jCjFuUQSXuKEiIoqIgiuyiYALiwJ6ZRUUWQQEzu+Pc5rbt+mZqbl3eqZn+v16nn6m69TpqlNVPXX6W+fUqZRSkCRJkqQu1ljoAkiSJElaPAwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEFpQSf4pyfeSXJLkL0nOT3JYkl368uyVpCT5m4Us66rqK/+WM+Q7uOUrSW5KckWSXyT5eJKHrupyh3zmObMs/8FJzuub3rKt93mzWc6qlGtVtnGcJFkjyfuTXNiO6WEz5F8/yWuTnJLkyiTXJjkzyQdG+f1Psm+SRw5JX+nYL3VJ7tr29dlt31+V5MQkr0+ywUKXb1T6zjslyV+TXJrk+0nemGTj1Vju0O/VapZ134Hy9r9G8j+yKudNaalba6ELoMmV5D+AA4CDgPcAVwNbAY8HHgl8c+FKt2AuBZ7U3q8P3AvYA/hRkneWUl7bl/frwEOBC2ex/L2o//cHzeIzb6Eep1Hai+HlWpVtHCdPA14GvBL4MXDZVBmTbAp8G7gL8AHgB8D1wH2B5wAPAx40onLuA7wN+M5A+nwc+7GQZAfgcOAS4EDgDGBtYHvgJcCdgP9csAKO3sHAR6gXFu9I3e5/B/4jyW6llB+twjKn+l7NhYcDNw6k/W4E64FVO29KS5oBhBbSq4DDSinP7Uv7DvC/SSa1dez6UsrxfdPHJPkQ8D5g7yQnlVK+BFBKuZQacIxEknVLKdeVUn49qnXMZNTbOA/u0/6+v5Ry0wx5PwVsCmxXSjm7L/27ST4I7DaKAk5nIY/9fEqyIXAo8Evg0aWUq/tmfyvJe4F/WJDCzZ/fD5x7vpbkQOD7wJeTbDWwXxbaT0opNyx0IVZVkrWBG4pP89UiNak/0jQe7gBcNGzGTD+2kmyT5OIkX05yq5a2Vuv+8ask1yW5IMl7e/NbnjOSfKxveoMkNyZZPrD8Hyb5Qt/0jMtu+e6R5OtJrmndAA4A1p3NThmyLwrwauBi4OV967pF954k/5rkp63rxRVJTk/ywjbvWOARwMP6mvyPHVjWDkm+mORPwE/avKm6sayTZP/U7mfXJDlisKtRW+a+A2m9LlB7zaJc/du4dpK3JjkvyfXt71tbhTy4jhcm2S+1C9GfknwtyeYD5Zlyn00nyS5Jfpza9e6K1K539+qbfx7Q2/Yb+7d5yLK2Ax4FvH0geADqd6CUclhf/jnbB0l6P2Be37f/923zpuq+1mW/znjs+9L3SPKz1G5Df0jyqdQWmVkvL8mDkxyd5LL2vfxNagA2necDGwH/PuxHcinl6lLK0X3ruHWSdyU5t+3/c1O7Oa3Rl2fHVrYnpXaL+kPqOeHTSW4/sB0vS/LL9l36Y5KTkjy5b/55SQ4eLNfgPknyt0m+0v4nr03y29T/51W6WFhKuRj4f8AmwO5969k5yZHt+F+Tel59ZZI1+8vW3g77Xj04yaFJlrdtPjPJ25OstyrlHCbJ3ZN8pu3z65Kc2r9PW56/ad+1c1s5fpPkQ6kBZS/PsUx9ftq3bzv7lzvV/82Lk7w7yQXAdcDtZ1HWOT220uryi6eFdAKwLMlvgK+WUs7q8qEkOwNfAj4DvKSU0mvG/jTwROBdwI+oV3/fAmwJPLXl+Q7whL7F7Ug9kW+W5G9LKWclWR94cFtez4zLTrIOcDSwHrXLwyXAC4GndNmu6ZRSrk9yDPC0JGsNu/KW5OGtnAdSK/01gHvTKingxW3+mq1cAH8eWMxngM9Su97MdH54LXAq8GxgY+Dt1Ku1f1dK+essNq9LufodAvxzW98PqF2c3gDcA/jXIWX8EbUL0MbAe6nb+AjotM+GSr1H5+vU79O/ALcB9gN+kOSBpZTfA08G/oPa/aF3D8tUV/Qf3f4ePt16+8zZPmif/TErurAALGd6My2zsyQvaOv9fFvuXdp2PSTJ1qWUq2axrNsAR1HPLXsBV1L/R2dqPXg0cFEp5aQO61irreO+1HPA6dTuPm+kXhR55cBHDgCOoB6XewHvpna9WdaW90zq/tuPerV/PeD+bVmzdQTwJ+DfgD8AmwG7snoXC78F3EDtQvfxlnYP4Bjgv4FrgW2pwfJGwN4tz3Tfq7tSzx0HU4/R3wFvasu9OVCZwZpJ+qdv6l14SrIF9QLIJdRuZ5dS/0+/lOSfSim9/7O7tDK9HPhjW//rgCNZ8T872/PTdF4PnAi8oC3v2lmUdRTHVlp1pRRfvhbkBfwtcBpQ2usP1B+vOw/k26vN/xvgmdR+4fsN5PnHlmfPgfRntvQHtuknt+m7ten3U3+0nQ28sKXt0vLce5bLfn6b3r4vzxrAz1v6ljPsj4OB5dPMf0dbziYD+2XLNv0q4PIZ1nEs8IMh6b1lvW+Kcp3XN71ly/sLYI2+9Ie19Of2pRVg34Hl9T6/1yzK1dvG+02xzDe09PsPrOO4gXyvaul36brPptiPJ7XvzFp9aXcH/grs35f2Vloj0gzL+1Ar17od8s7pPug7Tm+dxbHvusxpjz31R9TFwHcH8j285fuPWS5v2/59MIvj+Uvgxx3zPqutY4eB9NdTz00bt+kdW75DBvJ9gPqjO33Tp8ywzvOAg4ek37xPqPdoFOBJq/B9Hnr8++ZfCHxjinmhXmx4PfVH+Bpdlzvw+T2Am4A7zpB/X1bUGf2vT/fl+Tj1h/gdBz57NHDqNMteq++796C+9GMZfn7alyH/39P835zSO+6zKevqHFtfvkb1MnLVgim1xeFB1KuWb6NekXoycFSSNwz5yMupJ+aXlVLeNDBvF2rl/aXU7kZrtSuF32rzd2h/j6NWUr2RQR5JvYr8nYG0C0spv5rlsh8K/K709SMu9YrYzV2hVlPvcluZYv6JwIati8QTBrtJdPSVWeQ9tPR1NSul/JB6Ne8WI0bNod6+/vRAem968Ar41wemT29/79r+znqftRaqrYHPl76WoFLKucAPh5Rhrs31PlgVc7XMe1FbMD7Tn1hK+QFwPrPfl2dTr9J+JLVb1Baz/HwXu1DL9qMh54PeTdf9hu2rdandgqB+Bx+Y5L+TPDrJrVexXJcBvwHemeT5Se65issZJvSdd5JsmuQjSc6nnhv/Sg2Wb089ntMvLLldahewX1NbgP9KvQcoQNdyb09tKe693tg3bxdqK8IVA8foKOABSW7XyrFOkteldk39SyvH99sy7sXcO6yUMnj+7lLWUR5baZUYQGhBlVJuLKV8r5TyhlLKo6lNyKcD+/T3Q212B35P7b40aGNgHeAqaiXQe13S5t+xre9y4GfATknuRL2a+9322rHl3alNz2rZ1BtgLx5StmFpq2ILamV9+bCZpZTjgKe3fF8BLk3y7ST3n8U6ZjPa0VTbutksljFbvW4dg+W8aGB+z+C+uq79vRWs8j7bkPpDZ9i+umhIGbrojR5ztw5553QfrKK5WuZU2wKrsC9LKVdQ/38vAD4I/Lb1z3/q9J/kd9SrxF1sTD1Ofx14ndDm33Eg/0z76pPUbikPof5ovDz13q6u5QFuvlfqMdTWsXcAZ7U+/f82m+UMavcl3Il2jFLv8zic2hX0rdQLLg+mXgSCbt+BTwAvonYdfEz7/Etm8XmAk0spJ/W9zu2btzGwJ7c8Ru9p83vH6B3UVoRPU0f/244VXU5X5/9jKsO+5zOWdVTHVlod3gOhsVJKuSD1JucDqFeiTuib/VTgo8CxSR5ZSum/AfsyareAf5xi0Rf0vf8utY/pTu1zp1FP7Bsn6Q2V+ZG+/F2XfSG1L++gTYakzUq7v+LRwPFlmpFHSimHAoe2vuA7Uu/Z+GaSzcvMowDB1K0bwwzbrk2oLUk911GDr36DP7Bmo/dj7M6sfD/BndvfKYdJncoq7LM/UvfTnYfMu/OqlIE6fOvbqPfZvHeGvHO+D0aky7Hv35ZBd6b+YJrN8iilnAo8tV3F3ZZ6X8UXkjyglHLGFGX9NvCYJNuUUk6eIk/PZcC51HtQhjlvhs8PlrdQzzcfaRdNdqZ+Bz5PDSqgnn9W2vYktwiuSim/AfZMvTngAcBLgQ8mOa+U8o3ZlKvPY6ldzX7Qprei7tdnlVJubgVL8sQuC0sdeGI3aterA/rS/34VyzfMZdSWhHdNMb93zt4d+GQp5a195bjNLNZzbfvMOqWU6/vSpzrHDTu/dirriI6ttMpsgdCCmaZ7wb3b38ERmn5P/YG3BnVoy/5RWr5JvWK0wcBVqd5rMIDYjHpD3LGluoR6r8KbqZXld1Zh2T8GtkhycxeGdrVuqh8anbQK493UK1Xv6/KZUspVpZQjqD9MNmVFhXYd9SbNufC0rDzqzMOAzan7oed8aitPv8cPWVbXch3X/g7eaPnM9vd7HZYx1DT7bDDf1cDJwNOz8qgzd6PerHvcsM/NsO4TqDelvi5TPAwrSW8Y11Hsg+uZu+9FT5djfya11WqlbUnyD9Sr/P37sut3CYBSyg2tO+EbqeeM+0yVF/gY9R6sD7QuaitJHXWpd6P7N6ktVldNcT74wzTrmVYp5Y+llM9Tuz32b+uwbX8CU2jntFOBV7Skwc92kvoQuXdTL458riX3ulj9tS/f2qz4/vUb9r1al3qOHRxoYa9VKeMUvkm9Ef3nUxyjXivQrYeU49lDljfV+en89vfm/du6Qc5myN+uZQXm7thKq8sWCC2kM5J8l9p15FzgdtRRJV4EfKGU8tvBD5RSLkyyI/XH1rFJdiqlXFBKOTbJZ6lXkventlzcRO2WsCvwmrJilKfvUUdBeRQrms2hBhYvBX7brvb01tl12YdQRyD5cpLXUbs4vahtV1fr9AUgt2bFg+QeSr0ZcconGSfZj9oC8F3qVavNqaMAnVrq8xSg3vj84iT/Qr16fWUp5cxZlK/fbYHDknyEOvrKO6h90D/Zl+dzwBuSvB44ntqK84why+pUrlLKz9ux2LddYf4Rdd+8EfhsKeW02WxAx302zBupfduPSB0i9DbU4PMKZm5BmMqzqFfCT0zy36x4kNy9qaMdrU0drWxO90HzC+DxSb5JbWG5YCDoXhUzHvtSyo1J3kS9+v5paleSzaitMWdTu7p0Xl6SJ1BHuDmMek5Zn3o8r2TlwHYlpZTLWzenw4FT2v7vPUhuO+r/8aHU4/MZ6o/MY1KfD/EzauvAVtSHQP5TKeWarjspyUf7yncJdXCJZ7HiHqveth+U5H3U0XgewMAP7tbt7gBqy8U51B/pe1FHUOryILfN2rlnDWrXse2pA0MEeGIp5S8t3y+pP5zfluRG6g/wqR6wN/R7leR44JVJLqQGbs9hbrs+vol6nv5ekg9QW4U2pP7YvkcppfdU6W9SRwI8nbrPnsLwH/9TnZ++Qf2f/98k+1CDo1dTu7vOWVnn4NhKc6+MwZ3cvibzRa2UD6dWRtdSn0T9U+oJeJ2+fHvRRmHqS9uYeq/EWcBmLW0N6lN/f9aWd0V7/25q60H/un9C30hLLa03QtPBQ8raadnUeziOBK6hjqxxALWl4+aRhKbZHwezYkSRm6g/Kn5JHaVj+yH59+pfLvVq7FHUq4XXUft1f5yVR8a5cyvfle2zx061jwfKdV7f9JYt74uB/dt2XkP9QX33gc/equ2DC9s6P0/9QXbzyDkdy7VlX961qX2vz6f+eDm/Ta89pIzPGyjPji19x677bJrjtQv1R99f2vfhq8C9BvJ0GoWpL/9tqMNI/pT6/3Ad9Sr9AdQfE3O+D1raw6itKtey8sg+Ux37LsvsdOxb3j2o/0/XUbt0fArYdLbfJWrA/Xlq8HAt9bt5JPCQjvv/btRRkXo3915Fvcl5b+B2A2XZF/hVy3d5y7cvbWSuvn3y6Bn+b5dRR/m5pC3rXGpLY//61qD+0Dyf+r92FDVg6T9WG1MvYpzV8lxObcF5bIft7h/N6K/UH/U/oI7stdGQ/A9s86+hDpywH/A8bvm/OtX3akvqj+8r23Z/gPq/uNJ3aIqy7tvyrTVDvs2pLUu/pwbiF1JHNtqjL8+dqMHZH9vrM9T7MTqdn9q8h7djf03b93vQ8f+ma1lX59j68jWqV28YOUmSJEmakfdASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQkMlOTjJEXOwnH2TnDEXZZphPVsmKUm2HfW6Jl2SvZJcNaJlH5vkA33T5yV51YjWNbLtkCbBfNYTc7Uujc4o6/vBuqDV908b0brm5XfLYmcAsQi0E+e+87zalwF79JVhpR92Y+h3wKbAqV0/kGTHJOfNkOe8dqLqf/1pNcs6uI4F37dtX/S276Ykf05yWpIDktx9IPvngXt0XO5sA7unAK+dTdk7lmNYZdN5O6RxZz0xd9rFhWNnyDNYL5QkneufjuUY2QWUWZRhr77tuzHJn5KclORtSTYeyP5fwCM6LrdX59ypY1EeDHxwNmXvUIap6qfO2zHJ1lroAmg8lVKuWOgyzEYp5UbgohEtfj/gQ33TN41oPastydqllL+uxiL+DrgcuA3wAODlwOlJHl9KOQ6glPIX4C+rXdg+SdYppVxfSrl8Lpc7nVFshzRJFls9MQLPB/pbRVbn3DsySdYA0urJVXENsBUQ4HbUH/OvAZ6f5BGllF8ClFKuAua0Vbevbrh0Lpc7nVFsx1JkC8QilGSdJG9Pcn6S65L8Jsl/tHlrJvl4knOT/CXJ2Ule3U4gvc8fnOSIJG9IcnGSq5J8Isl6g3l676nR+Ev6rkRs2WVdHbdn/SSfbOW4OMlrW/kO7suzR5ITk1yZ5JIkX0yyWd/8la4k9F3deFSSnyS5pl012XoVdvmVpZSL+l6X9K13gyQfbWW6Mslx/VczktwxyWeTLG/76OdJnt03f6p9e4urM9Ns465JTkhyPfDYNu+JSU5Ocm07Pm9Lsk6Hbb2kbeM5pZQvATsCPwUOSrJmW/ZKXX+SbJHkq0kub/v5V0l2b7PPbX9PbGU9trfd7Ri/JslyYHlLH3YF8zZJPt2+Hxdl4IpchrQupO/KXVa0Mn2x5T1v2Ha0tBcmOSfJ9e3v84es6wXt+3d1+9/bA2nMZInVE0O2b90k729luzbJ8Uke3jd/7SQHJrmgbf/vkryzb/5TUltZ/9LOXccl2WSWxfjTQN1wWd/yN0vyuSR/bK+vJ7ln3/yt2nnzonYuOSXJE/rmHwvcDXhPb3+29GHnrZXqi16eVjecAVwP3KfNe3aSX7R9dlaS/+xwLErbvgtLKWeWUj4NPBT4E/DhvnKs1PUnyd8nOSa1RfvKJD9LslOSLYHvtmyXtrIf3NvuJB9K8l9JLgV+2NKHtcbcue3Xa9r3vL81bGjrQlauL6aqnwa3Y40kb2zfoeuSnJ5ktyHremqSo1t5fpHkMTPs10XNAGJxOgTYE3gF9aTwXOo/MtRj+nvgn9u81wOvA549sIxHUK8wPwp4KrAz8K4p1vcy4MfAJ6jdhDaldhnquq6ZvLeV58nAI1u5/nEgzzrAPm3eE4A7AZ/tsOx3AHsDWwOXAZ9JklmWb6i2nK8Dm7UyPQj4HvCdJJu2bLcCTmnz/w44APhIkke1+VPt29l4F/AG4N7AT5I8FvgM8IG2zucATwPePtttbFes3kft6vOgKbJ9ELg1sFNb38tZ8X3crv3dhbptT+n73COA+7d5j2JqrwB+ST2G+wBvT/KUafIPenD7+/xWhgcPy5TkydR99n7gftRj9cEkTxzI+ibgq9Tv4uepwdXdZlEeaT4stXpi0LuBf6Ge3x4EnA58s+/c+x/UOmV34J4t75kASe4MfI66j+4D7AB8ajXLc7Mkt6b+QL6Wug8fClwIfLvNg9rK+w3gMdR9/CXgy0nu3eY/hXphZT9W7M/ZuBW1XnghcF/g/NQLIm+nnsPuA7yS2pLw4tluY7tK/2FghyQbTZHt/6jbvR31GO1L3Se/o36foNYZm1K/Pz17UFs7/pH6HZ7Km4HDgQcCHwU+ORgwzGC6+qnfy4D/R91Xfw98hXqsHjiQ723AgdTjeSLwuSS3mUV5FpdSiq9F9KKeCAuwyyw+807g233TB1Mrktv0pe0BXAes35fniL75xwIfWIV17QucMU3+21Cvjuzel7Y+8Efg4Gk+d++2HzZv01u26W3b9I5t+rF9n3lY/2c67rvz2n65qu/1ujbvkW16vYHPnAq8epplfg742HT7tq/8d+pLm2obnzrw2e8BbxxI+6dW1kxRplusb8i+/uc2vRdwVd/804B9pljuSmUe+A5eCqw7kL7Svmj7/+iBPB8DftA3XYCnDTlur5ohz+B2/BA4aEg5B9f1jr7ptajN+3t0/U758jXqF0usnhhcF7WOuB7Ys2/+msCvgbe26QOBY4ad86gXIwpwt9XYx4XaBbK/bnhmm/cc4Oz+dbfyXdY7j06xzOOBN/RNr3Qea2krnbda2o70nb9bngJsM5Dvt8CzBtJeDvximjLdYn1983Zp69lu2HEE/gwsm+KzK5V54Dt02pD8K+2L9tn/HcjzbeDT7f2WDK97bq4LpskzuB2/B940pJyD63ph3/zNWtrDV/U7Nu4v74FYfB5E7YP/3akyJHkR8Dxq8+d6wNrA+QPZTiv1CkLPj6lX+bei/iDspOO6enn/kXrFpeeFwBntMyf0EkspV2dgBITUrkf7UK803IF6dQLgrrTuL1Po35YL2t+NZ/jMoP2Bj/dN9/rpb0O98n7pQKPGraj7kdRuP3tTr35tBqxL3c/HzmL9MzlpYHobYLskr+lLW4N6fO5MvSI0G72NK1PMPwD4cJJdqBX2V0opJ3dY7hmllOs65PvxkOnZtEB0dR/goIG0HwBPGki7+TtVSrmhNbMP3kwoLaQlVU+UUj4zkG2rtowf9hJKKTcm+TH1ajvUgONo4Kwk3wKOBL5RSrkJ+Bn1x+YZbd63gUPL7PvZ/z/gm33TF7e/2wB3B64cqBtuzYq6YX1qnfYE6tXvtal1R+f9OoMb6BtUpLUSbEFtAe+/p28tVpzjZ2umumF/4GNJllHrhi+VUn7VYbld6g8YXjc8vuNnO0lyO+Au9H3Xmh8Auw6kTfV7Y0kygFh8pv1HT/Iv1C4YrwJ+RL0C8BJqU+7cFmT26zqJGgD0XEw7mTL1Cah3oj2KepJ/FnAJtQvT96mV2XT6b2rrrWO2XfcuK6WcMyR9Deo2DHa3grovoO6bV1KbQE+nXqV6OzOfVHo3avcf77WnyHv1kHK9GfjikLyrciNar0L+zbCZpZSPJzmKejJ9NPCjJO8opew7w3IHy72qCrf8v5hqX3VZ1kxpgzdKFuwOqvGy1OqJWyy2/Z3y/7WUckrra78LtbX4EOBnSR7Tgo2dge2p3bKeC7wj9Ybgn3XfOi6apm44ldp9alDvAtR/tbK9itpacQ3wSWau026i2/nuurLyTdO9c9SLqMdhLtyXur/PGzazlLJvks8Aj6Pen7dPkheVUgYv1Ayai7rhFnVoklWtF2CWdUMppbTgccnWDQYQi88p1C/kTqx85aPn4cBPSin9Y+lvNSTf3ydZv5TS+0fdntok/Osp1ns9tQl2VdYF3DzqzUon2yTnUP/ptqPd0NT6iN6vryz3pgYMryul9PKM4gr0bJ0CbALcVEoZ+uOauo++Vkr5FNx838TfsqIvMgzft70f+pv2vR/sbzldue49RcU2K60F5eXUYzHlEIWllOXUPqgfbS0fL6M2A1/fsgxu32xsP2T6l33Tl9LXPzj1RsjB/sJ/7VCGX1KPV3/l9nDgF7MprDQGllQ9McQ5bV0Pp13YaOeqh1L73feWdSX1QsoX2026xwN/A5xVaj+THwM/TrIf8HNqS/FsAoipnAI8A/hDKWWqYb8fDnyy1MEqSNJruT6rL89UdcOtk9yulNK7UDVj3VBKuTjJ74GtSimf7L4pw7W+/S8Cjpuu5aaUcjY1QDqwtXw8j3qOnau64aCB6V7d0F+H9gzupxnLUEr5c5ILqMfrO32zJr5uMIBYZEopZyf5ArVZ8GXUE9XmwJbtR+pZwF5JHkc9ye5OvYnrjwOLWot68+d+1Oa5d1L7E04V+Z9H7RazJfUq+uWzWNd023NVkoOAdyX5A7V7zRuolV8vuv8ttd/tS5P8D7WryVu6rmOEvk1t1vxqklcDv6J2EdqF2r/3+9R99C+po4P8Afh3atP2T/uWcx633LfnUG802zfJ3tQ+lm/oWK79gCOSnA98gdqUfT9qP9VXz/DZjZOsRb035f7Af1K7Q+xaphgCMMkB1C4HZ1GH+NuFFSfWS6j9hB+bOvrRtWX2Qz9un+S1wKHUfrN7As/sm/8d6sgvPwJupLbwXDuwjPOARyU5jnplbth39D3UHxonA99q2/FMRtNdShqZpVZPDNm+q9uP0Xe2euNc6rlqE9qzApK8glqfnEq9gPCv1NaP5Um2p7aWHkVt4XgQtXvPXP0g/Ay1ZeGrSd5ErcO2AHYDPtx+VJ8FPDnJV1v59qF2Yep3HvCPST5NPW/9AfgJ9Qr9O5K8j3rDbteboPcF/jv1WUZHUlsutgY2K6W8Y5rPpd14DrABK4Zx3YBbdvHsfWA9aivLF9t2bEILJluW86l1/OOTfA34y0B3uS6ekuREapfgp1Fv9n8I1EA0yfHAa5L8upV1cBu71k/vAfZLcja1e9Ue1J4H28yyvEvKkm1aWeL2pF5lOZD6o/Vg6j8HwEeoPxr/jzoKwJbUUY4GHUe94vJd6ogC3wGm+3H5X9Ro/RfUyP6us1jXTF5F7Y50eCvPadRm7GsB2tWNZdQbgX9BPdG+YhXWM6faFaxdqfvuf6kjfHwBuBcr+j++lXp/xzeoNzdfTa1c+t1i35b6LIfdqaMf/YzaJel1Hct1FLVRkIAnAAAgAElEQVQf6E5t3SdQ78P4bYeP/5xa6f6UGoj8FLh/KeV703xmDeC/W/mPplbIy1pZbqCOhvI86j75apdtGLA/NZj5KXV/vqmUcmjf/FdSr0IeSw0yPkatGBjIsxM1KPspQ5RSDqMGeP/ZtuVlwItLKV9bhTJLC22p1RODXtOW+wlqkHB/6k3jvXu8rqTeo3ACNYB6IPC4Uso1wBXUQTWOoF4dfy/wllKHJ11tbR07UM9LX6Tu/0OADVkROL2Cep76PrV+OL697/cmauDxa9oV9VKflfNM6uhNpwMvAN7YsVwfo97g/SxqvfL99vlzZ/joran1wgXU/fkK4GvA/Up7BsQQN1K39xBq3fgVaovPK1pZfk+ty99GrTNW5QGE+1JHczoN+Dfg2aWUE/vmP6f9PZH6PVzpItws6qcDqUHEu6n3bT6ZOnjJnD44cLFJ/Q2kSdKacu9USnnCTHkXQpJ1qVcn3lNKmYuKRpI0C+NeT0haWHZh0oJL8iBqt6QTgNtSryzdljrGviRJksbIgnVhSvKZJGcmOSPJQb2741MdmPoU2NPS9+TgJMtSn2J5dhsWrJe+TeqTAc9pn52TB4VpXr2C2rXkO9S+kju0G3MlTRjrB0kabyPrwpRkwyluVOzN35UVYz3/H/C9UsqHWvq/U/uWPwQ4oJTykCR3oPaL35Z6483J1Iek/DHJCdT+ysdTbww6sJTyDSRJY8f6QZIWt1G2QJyU5P+SPHLYFZ9SypGloXZd2bzN2o06tFkppRwP3D710fSPpT6R9vJW8RwN7NLm3a6U8uO2rE9Sb7aVJI0n6wdJWsRGeQ/E31IfHvJS4H+SfAo4uJRyQX+m1jT9LOoVIqhP6/1dX5blLW269OVD0m8hyQuoIw6w/vrrb3Pve9971ht18mWXzSr/Nne846zXIUmjdPLJJ/+hlLLRAhZhrOqHuagbwPpB0uLXtX4YWQDRxow/gjoe/UbU8Xd/m+QfSikn9GX9ILV5ujd82bD+qcOeNDtT+rAyfZT6sCu23XbbctJJJ3Xaln455JBZ5T9p2bKZM0nSPGrPCFkw41Y/zEXdANYPkha/rvXDSG+iTrJBu7JzOPWK03Op4/X25u8DbMTKY/ovp4573LM5dXze6dI3H5IuSRpT1g+StHiNLIBoT048hfogrD1LKTuUUg4ppVzb5j+P2m/1GaWUm/o+ejiwZxttY3vgivZgmKOAnZNsmGRDYGfgqDbvyiTbt760e7JqD6uSJM0D6wdJWtxGeQ/EF4C92pP+hvkw9WFhP2730H25lLIfdZSMXamPvL8GeDbUpy8meQv1iYIA+7UnMkJ9AuHBwHrUkTscYUOSxpf1gyQtYqO8B+LwGeYPXXcbKeMlU8w7CDhoSPpJwP1WoZiSpHlm/SBJi9uCPUhOkiRJ0uJjACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLU2YIFEEkOSnJJkjP60vZN8vskp7bXrn3zXpvknCRnJnlsX/ouLe2cJHvP93ZIkuaW9YMkjbeFbIE4GNhlSPr7SikPbK8jAZLcF9gd+Lv2mQ8mWTPJmsD/AI8D7gs8o+WVJC1eB2P9IElja62FWnEp5XtJtuyYfTfgc6WU64Bzk5wDbNfmnVNK+Q1Aks+1vL+Y4+JKkuaJ9YMkjbcFCyCm8dIkewInAa8spfwR2Aw4vi/P8pYG8LuB9IfMSyk7yiGHdM5bli0bYUkkadFbUvWDJC1W43YT9YeArYAHAhcC723pGZK3TJM+VJIXJDkpyUmXXnrp6pZVkjR/RlY/WDdI0uyMVQBRSrm4lHJjKeUm4H9Z0Qy9HNiiL+vmwAXTpE+1/I+WUrYtpWy70UYbzW3hJUkjM8r6wbpBkmZnrAKIJJv2TT4Z6I3AcTiwe5J1k9wduCdwAnAicM8kd0+yDvVGusPns8ySpNGzfpCk8bFg90Ak+SywI3CnJMuBfYAdkzyQ2sx8HvBCgFLKz5N8gXrz2w3AS0opN7blvBQ4ClgTOKiU8vN53hRJ0hyyfpCk8baQozA9Y0jyx6fJ/zbgbUPSjwSOnMOiSZIWkPWDJI23serCJEmSJGm8GUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLU2YwBRJKHJVm/vd8jyf5J7jb6okmSxpn1gyRNpi4tEB8CrknyAODVwPnAJ0daKknSYmD9IEkTqEsAcUMppQC7AQeUUg4AbjvaYkmSFgHrB0maQGt1yHNlktcCewA7JFkTWHu0xZIkLQLWD5I0gbq0QPwLcB3w3FLKRcBmwHtGWipJ0mJg/SBJE2jGFohWKezfN/1b7OMqSRPP+kGSJtOUAUSSK4Ey1fxSyu1GUiJJ0lizfpCkyTZlAFFKuS1Akv2Ai4BPAQGeiTfJSdLEsn6QpMnW5R6Ix5ZSPlhKubKU8udSyoeAp466YJKksWf9IEkTqEsAcWOSZyZZM8kaSZ4J3DjqgkmSxp71gyRNoC4BxL8C/wxc3F5Pb2mSpMlm/SBJE2jaUZjamN5PLqXsNk/lkSQtAtYPkjS5pm2BKKXcSH3CqCRJN7N+kKTJ1eVJ1D9M8gHg88DVvcRSyikjK5UkaTGwfpCkCdQlgPiH9ne/vrQCPHLuiyNJWkSsHyRpAnV5EvVO81EQSdLiYv0gSZNpxlGYkmyQZP8kJ7XXe5NsMB+FkySNL+sHSZpMXYZxPQi4kjpU3z8DfwY+McpCSZIWBesHSZpAXe6B2KqU0v9k0TcnOXVUBZIkLRrWD5I0gbq0QPwlycN7E0keBvxldEWSJC0S1g+SNIG6tED8G3BIX7/WPwJ7jaxEkqTFwvpBkiZQl1GYTgUekOR2bfrPIy+VJGnsWT9I0mTqMgrT25PcvpTy51LKn5NsmOSt81E4SdL4sn6QpMnU5R6Ix5VS/tSbKKX8Edh1dEWSJC0S1g+SNIG6BBBrJlm3N5FkPWDdafJLkiaD9YMkTaAuN1F/GjgmySeAAjwHOGSkpZIkLQbWD5I0gbrcRP3uJKcBjwYCvKWUctTISyZJGmvWD5I0mbq0QAD8ErihlPLtJLdOcttSypWjLJgkaVGwfpCkCdNlFKbnA4cCH2lJmwGHjbJQkqTxZ/0gSZOpy03ULwEeBvwZoJRyNrDxKAslSVoUrB8kaQJ1CSCuK6Vc35tIshb1ZjlJ0mSzfpCkCdQlgDguyeuA9ZI8Bvgi8LXRFkuStAhYP0jSBOoSQOwNXAqcDrwQOBJ4wygLJUlaFKwfJGkCdRnG9Sbgf9sLgCQPA344wnJJksac9YMkTaYpA4gkawL/TB1V45ullDOSPAF4HbAe8KD5KaIkaZxYP0jSZJuuBeLjwBbACcCBSc4HHgrsXUpxmD5JmlzWD5I0waYLILYF7l9KuSnJrYA/AH9TSrlofoomSRpT1g+SNMGmu4n6+ta/lVLKtcBZVg6SJKwfJGmiTdcCce8kp7X3AbZq0wFKKeX+Iy+dJGkcWT9I0gSbLoC4z7yVQpK0mFg/SNIEmzKAKKWcP58FkSQtDtYPkjTZujxITpIkSZIAAwhJkiRJszBlAJHkmPb3XaNaeZKDklyS5Iy+tDskOTrJ2e3vhi09SQ5Mck6S05Js3feZZS3/2UmWjaq8kqTR1w/WDZI03qZrgdg0ySOAJyV5UJKt+19ztP6DgV0G0vYGjiml3BM4pk0DPA64Z3u9APgQ1EoF2Ad4CLAdsE+vYpEkjcSo64eDsW6QpLE13ShMb6KeoDcH9h+YV4BHru7KSynfS7LlQPJuwI7t/SHAscBrWvonSykFOD7J7ZNs2vIeXUq5HCDJ0dSK57OrWz5J0lAjrR+sGyRpvE03CtOhwKFJ3lhKecs8lmmTUsqFrQwXJtm4pW8G/K4v3/KWNlW6JGkEFqh+sG6QpDExXQsEAKWUtyR5ErBDSzq2lHLEaIs1VIaklWnSb7mA5AXUJm7uete7zl3JJGkCjUn9YN0gSfNsxlGYkrwDeBnwi/Z6WUsblYtb8zPt7yUtfTmwRV++zYELpkm/hVLKR0sp25ZStt1oo43mvOCSNEnmuX6wbpCkMdFlGNfHA48ppRxUSjmI2of08SMs0+FAb7SMZcBX+9L3bCNubA9c0ZqzjwJ2TrJhu0Fu55YmSRqt+awfrBskaUzM2IWpuT1weXu/wVytPMlnqTe63SnJcuqIGe8EvpDkucBvgae37EcCuwLnANcAzwYopVye5C3AiS3ffr2b5iRJIzfn9YN1gySNty4BxDuAnyb5LrVP6Q7Aa+di5aWUZ0wx61FD8hbgJVMs5yDgoLkokySps5HUD9YNkjTeutxE/dkkxwIPplYQrymlXDTqgkmSxpv1gyRNpk5dmFp/0sNHXBZJ0iJj/SBJk6fLTdSSJEmSBBhASJIkSZqFaQOIJGskOWO+CiNJWhysHyRpck0bQJRSbgJ+lsRHc0qSbmb9IEmTq8tN1JsCP09yAnB1L7GU8qSRlUqStBhYP0jSBOoSQLx55KWQJC1G1g+SNIG6PAfiuCR3A+5ZSvl2klsDa46+aJKkcWb9IEmTacZRmJI8HzgU+EhL2gw4bJSFkiSNP+sHSZpMXYZxfQnwMODPAKWUs4GNR1koSdKiYP0gSROoSwBxXSnl+t5EkrWAMroiSZIWCesHSZpAXQKI45K8DlgvyWOALwJfG22xJEmLgPWDJE2gLgHE3sClwOnAC4EjgTeMslCSpEXB+kGSJlCXUZhuSnII8BNq0/SZpRSbqCVpwlk/SNJkmjGASPJ44MPAr4EAd0/ywlLKN0ZdOEnS+LJ+kKTJ1OVBcu8FdiqlnAOQZCvg64AVhCRNNusHSZpAXe6BuKRXOTS/AS4ZUXkkSYuH9YMkTaApWyCSPKW9/XmSI4EvUPu4Ph04cR7KJkkaQ9YPkjTZpuvC9MS+9xcDj2jvLwU2HFmJJEnjzvpBkibYlAFEKeXZ81kQSdLiYP0gSZOtyyhMdwf+HdiyP38p5UmjK5YkadxZP0jSZOoyCtNhwMepTxe9abTFkSQtItYPkjSBugQQ15ZSDhx5SSRJi431gyRNoC4BxAFJ9gG+BVzXSyylnDKyUkmSFgPrB0maQF0CiL8HngU8khVN1KVNS5Iml/WDJE2gLgHEk4F7lFKuH3VhJEmLivWDJE2gLk+i/hlw+1EXRJK06Fg/SNIE6tICsQnwqyQnsnIfV4fpk6TJZv0gSROoSwCxz8hLIUlajKwfJGkCzRhAlFKOm4+CSJIWF+sHSZpMXZ5EfSV1VA2AdYC1gatLKbcbZcEkSePN+kGSJlOXFojb9k8n+Sdgu5GVSJK0KFg/SNJk6jIK00pKKYfhGN+SpAHWD5I0Gbp0YXpK3+QawLasaLKWJE0o6wdJmkxdRmF6Yt/7G4DzgN1GUhpJ0mJi/SBJE6jLPRDPno+CSJIWF+sHSZpMUwYQSd40zedKKeUtIyiPJGnMWT9I0mSbrgXi6iFp6wPPBe4IWEFI0mSyfpCkCTZlAFFKeW/vfZLbAi8Dng18DnjvVJ+TJC1t1g+SNNmmvQciyR2AVwDPBA4Bti6l/HE+CiZJGl/WD5I0uaa7B+I9wFOAjwJ/X0q5at5KJUkaW9YPkjTZpmuBeCVwHfAG4PVJeumh3iR3uxGXTZI0nqwfNBFyyCGd85Zly0ZYEmm8THcPxKyfUi1JWvqsHyRpslkJSJIkSerMAEKSJElSZwYQkiRJkjqbdhhXjbfZ3NwF3uAlSZKk1WcLhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktTZ2AYQSc5LcnqSU5Oc1NLukOToJGe3vxu29CQ5MMk5SU5LsvXCll6SNArWDZK08MY2gGh2KqU8sJSybZveGzimlHJP4Jg2DfA44J7t9QLgQ/NeUknSfLFukKQFNO4BxKDdgEPa+0OAf+pL/2Spjgdun2TThSigJGneWTdI0jwa5wCiAN9KcnKSF7S0TUopFwK0vxu39M2A3/V9dnlLW0mSFyQ5KclJl1566QiLLkkaEesGSVpgay10AabxsFLKBUk2Bo5O8qtp8mZIWrlFQikfBT4KsO22295iviRp7Fk3SNICG9sWiFLKBe3vJcBXgO2Ai3vNz+3vJS37cmCLvo9vDlwwf6WVJM0H6wZJWnhjGUAkWT/JbXvvgZ2BM4DDgWUt2zLgq+394cCebcSN7YEres3ZkqSlwbpBksbDuHZh2gT4ShKoZfy/Uso3k5wIfCHJc4HfAk9v+Y8EdgXOAa4Bnj3/RZYkjZh1gySNgbEMIEopvwEeMCT9MuBRQ9IL8JJ5KJokaYFYN0jSeBjLLkySJEmSxpMBhCRJkqTOxrILkyRJ0lzLIYfMnEnSjGyBkCRJktSZLRCSJEmrabatG2XZspkzSWPKFghJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLUmQGEJEmSpM4MICRJkiR1ZgAhSZIkqTMDCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZAYQkSZKkzgwgJEmSJHVmACFJkiSpMwMISZIkSZ0ZQEiSJEnqzABCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEKSJElSZwYQkiRJkjozgJAkSZLU2VoLXQBJUpVDDplV/rJs2YhKIknS1GyBkCRJktSZAYQkSZKkzgwgJEmSJHXmPRBjZLb9nyVJkqT5ZguEJEmSpM4MICRJkiR1ZgAhSZIkqTPvgZAkSYuS9w5KC8MWCEmSJEmdGUBIkiRJ6swAQpIkSVJnBhCSJEmSOjOAkCRJktSZozBJkiSNudmMOFWWLRthSSRbICRJkiTNgi0QkiRJ88xnWGgxswVCkiRJUmcGEJIkSZI6M4CQJEmS1JkBhCRJkqTODCAkSZIkdeYoTJoTsx1NwjGqJUmSFidbICRJkiR1ZgAhSZIkqTO7MEmSJC0hdivWqBlAaCifkClJkqRh7MIkSZIkqTMDCEmSJEmdLZkuTEl2AQ4A1gQ+Vkp55wIXSZI0BqwfFhe70Erjb0kEEEnWBP4HeAywHDgxyeGllF8sbMkkSQtpUusHb6KVNEpLIoAAtgPOKaX8BiDJ54DdgCVdQUiSZjS29cNsfuQv5h/4tigsPZPy3dXUlkoAsRnwu77p5cBDFqgsmmOjvpLmiVBa0qwf5pgBgWZjMbeGLeayj1pKKQtdhtWW5OnAY0spz2vTzwK2K6X8+0C+FwAvaJP3As5chdXdCfjDahR3sZiU7YTJ2Va3c+lZ1W29Wyllo7kuzDjqUj/MUd0Ak/Xdm4n7YgX3xQruixXGdV90qh+WSgvEcmCLvunNgQsGM5VSPgp8dHVWlOSkUsq2q7OMxWBSthMmZ1vdzqVnkrZ1NcxYP8xF3QAej37uixXcFyu4L1ZY7PtiqQzjeiJwzyR3T7IOsDtw+AKXSZK08KwfJGmOLYkWiFLKDUleChxFHabvoFLKzxe4WJKkBWb9IElzb0kEEACllCOBI+dhVavdzL1ITMp2wuRsq9u59EzStq4y64cF4b5YwX2xgvtihUW9L5bETdSSJEmS5sdSuQdCkiRJ0jwwgJiFJLskOTPJOUn2XujydJFkiyTfTfLLJD9P8rKWfockRyc5u/3dsKUnyYFtG09LsnXfspa1/GcnWdaXvk2S09tnDkyS+d/Sm8uyZpKfJjmiTd89yU9amT/fbqIkybpt+pw2f8u+Zby2pZ+Z5LF96WNx/JPcPsmhSX7VjutDl+LxTPKf7Tt7RpLPJrnVUjmeSQ5KckmSM/rSRn4Mp1qHVt+4nB9GadTf28Ui81CvLhbtvHxCkp+1ffHmlj5n5+rFJiP8HTJWSim+OryoN9/9GrgHsA7wM+C+C12uDuXeFNi6vb8tcBZwX+DdwN4tfW/gXe39rsA3gADbAz9p6XcAftP+btjeb9jmnQA8tH3mG8DjFnB7XwH8H3BEm/4CsHt7/2Hg39r7FwMfbu93Bz7f3t+3Hdt1gbu3Y77mOB1/4BDgee39OsDtl9rxpD7861xgvb7juNdSOZ7ADsDWwBl9aSM/hlOtw9dqH8+xOT+MeDtH+r1dLC/moV5dLK+2Tbdp79cGftK2cU7O1Qu9fau4T0byO2Sht+sW27nQBVgsr1YZH9U3/VrgtQtdrlXYjq8Cj6E+KGnTlrYpcGZ7/xHgGX35z2zznwF8pC/9Iy1tU+BXfekr5ZvnbdscOAZ4JHBEO7H9AVhr8BhSR2R5aHu/VsuXwePayzcuxx+4HfWHdQbSl9TxZMXTg+/Qjs8RwGOX0vEEtmTlH2IjP4ZTrcPXah/LBf8+zeO2juR7u9DbtZr7ZE7r1YXentXYD7cGTqE+6X1OztULvU2rsA9G9jtkobdt8GUXpu56P2h6lre0RaM1jz2IeoVgk1LKhQDt78Yt21TbOV368iHpC+H9wKuBm9r0HYE/lVJuaNP9Zbt5e9r8K1r+2W7/fLsHcCnwidZE+rEk67PEjmcp5ffAfwG/BS6kHp+TWXrHs998HMOp1qHVM47fp/kyV9/bRWlE9eqi0rrsnApcAhxNvWI+V+fqxWaUv0PGigFEd8P6gS+aIayS3Ab4EvDyUsqfp8s6JK2sQvq8SvIE4JJSysn9yUOylhnmjfV2Uq9SbA18qJTyIOBqalP5VBbldra+w7tRm2/vAqwPPG5I1sV+PLtYytu2VLjPb2nJfz9HWK8uKqWUG0spD6Refd8OuM+wbO3vkt0X8/A7ZKwYQHS3HNiib3pz4IIFKsusJFmbepL7TCnlyy354iSbtvmbUq8cwNTbOV365kPS59vDgCclOQ/4HLX58P3A7ZP0nnfSX7abt6fN3wC4nNlv/3xbDiwvpfykTR9KDSiW2vF8NHBuKeXSUspfgS8D/8DSO5795uMYTrUOrZ5x/D7Nl7n63i4qI65XF6VSyp+AY6n3QMzVuXoxGfXvkLFiANHdicA9293061BveDl8gcs0oyQBPg78spSyf9+sw4Fl7f0yah/OXvqebdSI7YErWlPsUcDOSTZsV4d3pvbjuxC4Msn2bV179i1r3pRSXltK2byUsiX12HynlPJM4LvA01q2we3sbf/TWv7S0ndvoyPcHbgn9YbUsTj+pZSLgN8luVdLehTwC5bY8aR2Xdo+ya1bOXrbuaSO54D5OIZTrUOrZxy/T/NlTr63813o1THqenVeNmKOJNkoye3b+/WoF39+ydydqxeNefgdMl4W+iaMxfSijqRwFrV/3+sXujwdy/xwatPXacCp7bUrtZ/dMcDZ7e8dWv4A/9O28XRg275lPQc4p72e3Ze+LXBG+8wHGLjBdwG2eUdWjH5wD+o/3jnAF4F1W/qt2vQ5bf49+j7/+rYtZ9I3AtG4HH/ggcBJ7ZgeRh29Y8kdT+DNwK9aWT5FHZFiSRxP4LPUezv+Sr3a9Nz5OIZTrcPXnBzTsTg/jHgbR/q9XSwv5qFeXSwv4P7AT9u+OAN4U0ufs3P1Ynwxot8h4/TySdSSJEmSOrMLkyRJkqTODCAkSZIkdWYAIUmSJKkzAwhJkiRJnRlASJIkSerMAEJaDUmOTfLYgbSXJ/ngNJ+5avQlkyQtJOsHLWUGENLq+Sz1gTH9dm/pkqTJZf2gJcsAQlo9hwJPSLIuQJItgbsApyY5JskpSU5PstvgB5PsmOSIvukPJNmrvd8myXFJTk5yVJJN52NjJElzxvpBS5YBhLQaSimXUZ8guUtL2h34PPAX4MmllK2BnYD3JkmXZSZZG/hv4GmllG2Ag4C3zXXZJUmjY/2gpWythS6AtAT0mqm/2v4+Bwjw9iQ7ADcBmwGbABd1WN69gPsBR7c6ZU3gwrkvtiRpxKwftCQZQEir7zBg/yRbA+uVUk5pTc0bAduUUv6a5DzgVgOfu4GVWwF78wP8vJTy0NEWW5I0YtYPWpLswiStplLKVcCx1Kbk3s1xGwCXtMphJ+BuQz56PnDfJOsm2QB4VEs/E9goyUOhNlkn+btRboMk6f+3c8coCMRAGEb/AY/owcQ7iGBh4zUERRAES29hExtBsJpiRZT3ykBgtxo+EjI984F/5QQCprFOss3rxY1Vkl1V7SUm4XQAAABkSURBVJMck1zeN4wxblW1SXJKck1yeK7fq2qeZPkcHLMkiyTnj/8FAFMzH/g7Ncb49jcAAAA/whUmAACgTUAAAABtAgIAAGgTEAAAQJuAAAAA2gQEAADQJiAAAIA2AQEAALQ9AGaz6XodUMKrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83c8966588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)\n",
    "\n",
    "# Visualize skewed continuous features of original data\n",
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For highly-skewed feature distributions such as `'capital-gain'` and `'capital-loss'`, it is common practice to apply a <a href=\"https://en.wikipedia.org/wiki/Data_transformation_(statistics)\">logarithmic transformation</a> on the data so that the very large and very small values do not negatively affect the performance of a learning algorithm. Using a logarithmic transformation significantly reduces the range of values caused by outliers. Care must be taken when applying this transformation however: The logarithm of `0` is undefined, so we must translate the values by a small amount above `0` to apply the the logarithm successfully.\n",
    "\n",
    "Run the code cell below to perform a transformation on the data and visualize the results. Again, note the range of values and how they are distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8399666cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Visualize the new log distributions\n",
    "vs.distribution(features_log_transformed, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Numerical Features\n",
    "In addition to performing transformations on features that are highly skewed, it is often good practice to perform some type of scaling on numerical features. Applying a scaling to the data does not change the shape of each feature's distribution (such as `'capital-gain'` or `'capital-loss'` above); however, normalization ensures that each feature is treated equally when applying supervised learners. Note that once scaling is applied, observing the data in its raw form will no longer have the same original meaning, as exampled below.\n",
    "\n",
    "Run the code cell below to normalize each numerical feature. We will use [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "3  0.493151            Private            11th       0.400000   \n",
       "4  0.150685            Private       Bachelors       0.800000   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.667492           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  \n",
       "3      0.000000           0.0        0.397959   United-States  \n",
       "4      0.000000           0.0        0.397959            Cuba  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Data Preprocessing\n",
    "\n",
    "From the table in **Exploring the Data** above, we can see there are several features for each record that are non-numeric. Typically, learning algorithms expect input to be numeric, which requires that non-numeric features (called *categorical variables*) be converted. One popular way to convert categorical variables is by using the **one-hot encoding** scheme. One-hot encoding creates a _\"dummy\"_ variable for each possible category of each non-numeric feature. For example, assume `someFeature` has three possible entries: `A`, `B`, or `C`. We then encode this feature into `someFeature_A`, `someFeature_B` and `someFeature_C`.\n",
    "\n",
    "|   | someFeature |                    | someFeature_A | someFeature_B | someFeature_C |\n",
    "| :-: | :-: |                            | :-: | :-: | :-: |\n",
    "| 0 |  B  |  | 0 | 1 | 0 |\n",
    "| 1 |  C  | ----> one-hot encode ----> | 0 | 0 | 1 |\n",
    "| 2 |  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "Additionally, as with the non-numeric features, we need to convert the non-numeric target label, `'income'` to numerical values for the learning algorithm to work. Since there are only two possible categories for this label (\"<=50K\" and \">50K\"), we can avoid using one-hot encoding and simply encode these two categories as `0` and `1`, respectively. In code cell below, you will need to implement the following:\n",
    " - Use [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) to perform one-hot encoding on the `'features_log_minmax_transform'` data.\n",
    " - Convert the target label `'income_raw'` to numerical entries.\n",
    "   - Set records with \"<=50K\" to `0` and records with \">50K\" to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0  0.301370       0.800000      0.667492           0.0        0.397959   \n",
       "1  0.452055       0.800000      0.000000           0.0        0.122449   \n",
       "2  0.287671       0.533333      0.000000           0.0        0.397959   \n",
       "3  0.493151       0.400000      0.000000           0.0        0.397959   \n",
       "4  0.150685       0.800000      0.000000           0.0        0.397959   \n",
       "\n",
       "   workclass_ Federal-gov  workclass_ Local-gov  workclass_ Private  \\\n",
       "0                       0                     0                   0   \n",
       "1                       0                     0                   0   \n",
       "2                       0                     0                   1   \n",
       "3                       0                     0                   1   \n",
       "4                       0                     0                   1   \n",
       "\n",
       "   workclass_ Self-emp-inc  workclass_ Self-emp-not-inc  \\\n",
       "0                        0                            0   \n",
       "1                        0                            1   \n",
       "2                        0                            0   \n",
       "3                        0                            0   \n",
       "4                        0                            0   \n",
       "\n",
       "              ...              native-country_ Portugal  \\\n",
       "0             ...                                     0   \n",
       "1             ...                                     0   \n",
       "2             ...                                     0   \n",
       "3             ...                                     0   \n",
       "4             ...                                     0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                        0                           0  \n",
       "1                        0                           0  \n",
       "2                        0                           0  \n",
       "3                        0                           0  \n",
       "4                        0                           0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "categorical = ['workclass', 'education_level', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "features_final = pd.get_dummies(features_log_minmax_transform, categorical)\n",
    "\n",
    "display(features_final.head(n = 5))\n",
    "\n",
    "# TODO: Encode the 'income_raw' data to numerical values\n",
    "income = pd.get_dummies(income_raw, drop_first=True)\n",
    "income = income['>50K']\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Uncomment the following line to see the encoded feature names\n",
    "# print encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data\n",
    "Now all _categorical variables_ have been converted into numerical features, and all numerical features have been normalized. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing.\n",
    "\n",
    "Run the code cell below to perform this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Evaluating Model Performance\n",
    "In this section, we will investigate four different algorithms, and determine which is best at modeling the data. Three of these algorithms will be supervised learners of your choice, and the fourth algorithm is known as a *naive predictor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and the Naive Predictor\n",
    "*CharityML*, equipped with their research, knows individuals that make more than \\$50,000 are most likely to donate to their charity. Because of this, *CharityML* is particularly interested in predicting who makes more than \\$50,000 accurately. It would seem that using **accuracy** as a metric for evaluating a particular model's performace would be appropriate. Additionally, identifying someone that *does not* make more than \\$50,000 as someone who does would be detrimental to *CharityML*, since they are looking to find individuals willing to donate. Therefore, a model's ability to precisely predict those that make more than \\$50,000 is *more important* than the model's ability to **recall** those individuals. We can use **F-beta score** as a metric that considers both precision and recall:\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "In particular, when $\\beta = 0.5$, more emphasis is placed on precision. This is called the **F$_{0.5}$ score** (or F-score for simplicity).\n",
    "\n",
    "Looking at the distribution of classes (those who make at most \\$50,000, and those who make more), it's clear most individuals do not make more than \\$50,000. This can greatly affect **accuracy**, since we could simply say *\"this person does not make more than \\$50,000\"* and generally be right, without ever looking at the data! Making such a statement would be called **naive**, since we have not considered any information to substantiate the claim. It is always important to consider the *naive prediction* for your data, to help establish a benchmark for whether a model is performing well. That been said, using that prediction would be pointless: If we predicted all people made less than \\$50,000, *CharityML* would identify no one as donors. \n",
    "\n",
    "\n",
    "#### Note: Recap of accuracy, precision, recall\n",
    "\n",
    "** Accuracy ** measures how often the classifier makes the correct prediction. Itâ€™s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).\n",
    "\n",
    "** Precision ** tells us what proportion of messages we classified as spam, actually were spam.\n",
    "It is a ratio of true positives(words classified as spam, and which are actually spam) to all positives(all words classified as spam, irrespective of whether that was the correct classificatio), in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Positives)]`\n",
    "\n",
    "** Recall(sensitivity)** tells us what proportion of messages that actually were spam were classified by us as spam.\n",
    "It is a ratio of true positives(words classified as spam, and which are actually spam) to all the words that were actually spam, in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Negatives)]`\n",
    "\n",
    "For classification problems that are skewed in their classification distributions like in our case, for example if we had a 100 text messages and only 2 were spam and the rest 98 weren't, accuracy by itself is not a very good metric. We could classify 90 messages as not spam(including the 2 that were spam but we classify them as not spam, hence they would be false negatives) and 10 as spam(all 10 false positives) and still get a reasonably good accuracy score. For such cases, precision and recall come in very handy. These two metrics can be combined to get the F1 score, which is weighted average(harmonic mean) of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score(we take the harmonic mean as we are dealing with ratios)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Naive Predictor Performace\n",
    "* If we chose a model that always predicted an individual made more than $50,000, what would  that model's accuracy and F-score be on this dataset? You must use the code cell below and assign your results to `'accuracy'` and `'fscore'` to be used later.\n",
    "\n",
    "** Please note ** that the the purpose of generating a naive predictor is simply to show what a base model without any intelligence would look like. In the real world, ideally your base model would be either the results of a previous model or could be based on a research paper upon which you are looking to improve. When there is no benchmark model set, getting a result better than random choice is a place you could start from.\n",
    "\n",
    "** HINT: ** \n",
    "\n",
    "* When we have a model that always predicts '1' (i.e. the individual makes more than 50k) then our model will have no True Negatives(TN) or False Negatives(FN) as we are not making any negative('0' value) predictions. Therefore our Accuracy in this case becomes the same as our Precision(True Positives/(True Positives + False Positives)) as every prediction that we have made with value '1' that should have '0' becomes a False Positive; therefore our denominator in this case is the total number of records we have in total. \n",
    "* Our Recall score(True Positives/(True Positives + False Negatives)) in this setting becomes 1 as we have no False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.2478, F-score: 0.2917]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TP = np.sum(income) # Counting the ones as this is the naive case. Note that 'income' is the 'income_raw' data \n",
    "encoded to numerical values done in the data preprocessing step.\n",
    "FP = income.count() - TP # Specific to the naive case\n",
    "\n",
    "TN = 0 # No predicted negatives in the naive case\n",
    "FN = 0 # No predicted negatives in the naive case\n",
    "'''\n",
    "# TODO: Calculate accuracy, precision and recall\n",
    "TP = np.sum(income)\n",
    "FP = income.count() - TP\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "accuracy = TP/income.count()\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "\n",
    "#print(\"Accuracy: {:.4f}, Recall: {:.4f}, Precision: {:0.4f}\".format(accuracy, recall, precision))\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "beta = 0.5\n",
    "beta_squared = np.square(beta)\n",
    "\n",
    "fscore = (1 + beta_squared)*((precision*recall)/(beta_squared*precision + recall))\n",
    "\n",
    "# Print the results \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: **  The naive predictor's accuracy:  0.2478, F-score: 0.2917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Supervised Learning Models\n",
    "**The following are some of the supervised learning models that are currently available in** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **that you may choose from:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent Classifier (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Model Application\n",
    "List three of the supervised learning models above that are appropriate for this problem that you will test on the census data. For each model chosen\n",
    "\n",
    "- Describe one real-world application in industry where the model can be applied. \n",
    "- What are the strengths of the model; when does it perform well?\n",
    "- What are the weaknesses of the model; when does it perform poorly?\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?\n",
    "\n",
    "** HINT: **\n",
    "\n",
    "Structure your answer in the same format as above^, with 4 parts for each of the three models you pick. Please include references with your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** I believe the most appropriate models to solve this problem are K-Nearest Neighbours (kNN), Logistic Regression and the ensemble method Gradient Boosting.\n",
    "\n",
    "**K-Nearest Neighbors (kNNs):** \n",
    "- Applications:\n",
    " - have been used in the industry successfully for recommender systems (ref: https://towardsdatascience.com/how-did-we-build-book-recommender-systems-in-an-hour-part-2-k-nearest-neighbors-and-matrix-c04b3c2ef55c ). If you know a user likes a particular item, then you can recommend similar items for them. \n",
    "- Strengths:\n",
    " - This model is popular due to its simplicity, requring only one parameter (k) estimated. \n",
    " - The model is effective where there is a large training database, or many combinations of predictor variables. It is also robust to noisy training data. \n",
    "- Weaknesses:\n",
    " - It provides no information on which predictors are most effective in making a good classification.\n",
    " - The computation cost is high, number of records required increases faster than linearly. \n",
    " - We need to determine the k parameter. \n",
    "- What makes it a good canditate: \n",
    " - It is good to begining with a simple model, as it can be used as 'weak predictors' for more complicated models like ensemble methods like bagging and random forests\n",
    "\n",
    "**Logistic Regression:** \n",
    "- Applications:\n",
    " - In industry, logistic regression is well-known, widely used in healthcare, for example: applying logictics regression to predict patient readmissions (ref: https://hub.packtpub.com/healthcare-analytics-logistic-regression-to-reduce-patient-readmissions ). \n",
    "- Strengths:\n",
    " - It is a fast model to learn and effective on many binary classification problems.\n",
    " - In addition to classification, it's also useful for scoring/ranking due to it's outputs have a nice probabilistic interpretation.\n",
    " - The model is easy to implement and fairly straightforward.\n",
    " - The algorithm can be regularized to avoid overfitting. \n",
    " - Logistic models can be updated easily with new data using stochastic gradient descent. \n",
    "- Weaknesses:\n",
    " - We need to choose correct set of features in order to have a successful model, if we include the wrong features, the model will have little to no predictive value. \n",
    " - The model also does not work well if features are highly correlated with one another.\n",
    " - The model also perform badly when the data is non-linearly separable.\n",
    "- What makes it a good canditate:\n",
    " - The model is useful as a standard benchmark and a starting point to compare with more complex models. \n",
    "\n",
    "**Gradient Boosting:** is an essembly technique which builds a sequence of weak predictor (typically decision trees) models to form a more powerful model. \n",
    "- Applications:\n",
    " - The model is applied widely in industry, one of its applications is sales forecasting in retail demand and sales prediction (ref: https://pdfs.semanticscholar.org/76a2/44f4da1d29170a9f91d381a5e12dc7ad2c0f.pdf ). \n",
    "- Strengths:\n",
    " - The model is often providing good prediction accuracy for many prediction tasks including non-linear. \n",
    " - The model can optimize on different loss functions and provides several hyperparameter tuning options making the model is very flexible.\n",
    " - The model works great with both catagorical, numerical and mising values so no pre-processing  or imputation are required. \n",
    "- Weaknesses:\n",
    " - The model can overfit a training dataset quickly if the data is noisy.\n",
    " - The model generally takes longer to train because of the fact that trees are built sequentially.\n",
    "- What makes it a good canditate:\n",
    " - The data contains heterogenous features with a mix of categorical and numerical features. \n",
    " - The model is a strong predictor and it is the wining model for many classification completitions in Kaggle. \n",
    " - We can tune many hyperparameters in order to achieve a good performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Creating a Training and Predicting Pipeline\n",
    "To properly evaluate the performance of each model you've chosen, it's important that you create a training and predicting pipeline that allows you to quickly and effectively train models using various sizes of training data and perform predictions on the testing data. Your implementation here will be used in the following section.\n",
    "In the code block below, you will need to implement the following:\n",
    " - Import `fbeta_score` and `accuracy_score` from [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    " - Fit the learner to the sampled training data and record the training time.\n",
    " - Perform predictions on the test data `X_test`, and also on the first 300 training points `X_train[:300]`.\n",
    "   - Record the total prediction time.\n",
    " - Calculate the accuracy score for both the training subset and testing set.\n",
    " - Calculate the F-score for both the training subset and testing set.\n",
    "   - Make sure that you set the `beta` parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size]) \n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end-start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end-start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Initial Model Evaluation\n",
    "In the code cell, you will need to implement the following:\n",
    "- Import the three supervised learning models you've discussed in the previous section.\n",
    "- Initialize the three models and store them in `'clf_A'`, `'clf_B'`, and `'clf_C'`.\n",
    "  - Use a `'random_state'` for each model you use, if provided.\n",
    "  - **Note:** Use the default settings for each model â€” you will tune one specific model in a later section.\n",
    "- Calculate the number of records equal to 1%, 10%, and 100% of the training data.\n",
    "  - Store those values in `'samples_1'`, `'samples_10'`, and `'samples_100'` respectively.\n",
    "\n",
    "**Note:** Depending on which algorithms you chose, the following implementation may take some time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier trained on 361 samples.\n",
      "KNeighborsClassifier trained on 3617 samples.\n",
      "KNeighborsClassifier trained on 36177 samples.\n",
      "LogisticRegression trained on 361 samples.\n",
      "LogisticRegression trained on 3617 samples.\n",
      "LogisticRegression trained on 36177 samples.\n",
      "GradientBoostingClassifier trained on 361 samples.\n",
      "GradientBoostingClassifier trained on 3617 samples.\n",
      "GradientBoostingClassifier trained on 36177 samples.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8396d882b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Import the three supervised learning models from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC \n",
    "# TODO: Initialize the three models\n",
    "\n",
    "clf_A = KNeighborsClassifier()\n",
    "clf_B = LogisticRegression(random_state=30)\n",
    "clf_C = GradientBoostingClassifier(random_state=30)\n",
    "\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# HINT: samples_100 is the entire training set i.e. len(y_train)\n",
    "# HINT: samples_10 is 10% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "# HINT: samples_1 is 1% of samples_100 (ensure to set the count of the values to be `int` and not `float`)\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = (int)(len(y_train) * 0.1)\n",
    "samples_1 = (int)(len(y_train) * 0.01)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Improving Results\n",
    "In this final section, you will choose from the three supervised learning models the *best* model to use on the student data. You will then perform a grid search optimization for the model over the entire training set (`X_train` and `y_train`) by tuning at least one parameter to improve upon the untuned model's F-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Choosing the Best Model\n",
    "\n",
    "* Based on the evaluation you performed earlier, in one to two paragraphs, explain to *CharityML* which of the three models you believe to be most appropriate for the task of identifying individuals that make more than \\$50,000. \n",
    "\n",
    "** HINT: ** \n",
    "Look at the graph at the bottom left from the cell above(the visualization created by `vs.evaluate(results, accuracy, fscore)`) and check the F score for the testing set when 100% of the training set is used. Which model has the highest score? Your answer should include discussion of the:\n",
    "* metrics - F score on the testing when 100% of the training data is used, \n",
    "* prediction/training time\n",
    "* the algorithm's suitability for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** From the graphs above, it is clear that the Gradient Boosting Classifier is the most appropriate for the task of indentifying individuals that make more than $50,000. This is because it achieved the highest scores on both accuracy and F-score for testing set among all other evaluated models. It, also, is one of the fastest for prediction time. While the model is the slowest for training time, which was expected due to multiple trees were built sequentially, and it is a trade off for a better prediction. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Describing the Model in Layman's Terms\n",
    "\n",
    "* In one to two paragraphs, explain to *CharityML*, in layman's terms, how the final model chosen is supposed to work. Be sure that you are describing the major qualities of the model, such as how the model is trained and how the model makes a prediction. Avoid using advanced mathematical jargon, such as describing equations.\n",
    "\n",
    "** HINT: **\n",
    "\n",
    "When explaining your model, if using external resources please include all citations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** \n",
    " \n",
    "Gradient boosting is a type of boosting technique. It relies on the intuition that a stronger model possible next model, when combined with previous models, minimizes a pre-defined loss function. The key idea is to set the target outcomes for  next model in order to minimize the error from the previous model. Each new model takes a step in the direction that minimizes prediction error, in the space of possible predictions for each training case.\n",
    "\n",
    "Gradient boosting involves three elements:\n",
    "- A loss function to be optimized. Any loss function which is differentiable can be used. We can use standard loss functions are supported and you can define your own. For example, regression may use a squared error and classification may use logarithmic loss.\n",
    "- A weak learner to make predictions. Decision trees are normally used as the weak learner in gradient boosting.\n",
    "- An additive model to add weak learners to minimize the loss function. The model consists of ensemble of trees where trees are added one at a time, and existing trees in the model stays the same. A gradient descent procedure is used to minimize the loss when adding trees. After calculating error or loss, the weights are updated to minimize that error. After calculating the loss, to perform the gradient descent procedure, we must add a tree to the model that reduces the loss (i.e. follow the gradient). \n",
    "\n",
    "rerferences:\n",
    "1. https://en.wikipedia.org/wiki/Gradient_boosting\n",
    "2. https://www.displayr.com/gradient-boosting-the-coolest-kid-on-the-machine-learning-block/\n",
    "3. https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/\n",
    "4. https://hackernoon.com/gradient-boosting-and-xgboost-90862daa6c77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Model Tuning\n",
    "Fine tune the chosen model. Use grid search (`GridSearchCV`) with at least one important parameter tuned with at least 3 different values. You will need to use the entire training set for this. In the code cell below, you will need to implement the following:\n",
    "- Import [`sklearn.grid_search.GridSearchCV`](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html) and [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Initialize the classifier you've chosen and store it in `clf`.\n",
    " - Set a `random_state` if one is available to the same state you set before.\n",
    "- Create a dictionary of parameters you wish to tune for the chosen model.\n",
    " - Example: `parameters = {'parameter' : [list of values]}`.\n",
    " - **Note:** Avoid tuning the `max_features` parameter of your learner if that parameter is available!\n",
    "- Use `make_scorer` to create an `fbeta_score` scoring object (with $\\beta = 0.5$).\n",
    "- Perform grid search on the classifier `clf` using the `'scorer'`, and store it in `grid_obj`.\n",
    "- Fit the grid search object to the training data (`X_train`, `y_train`), and store it in `grid_fit`.\n",
    "\n",
    "**Note:** Depending on the algorithm chosen and the parameter list, the following implementation may take some time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 125 candidates, totalling 1250 fits\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.17357762777242045, total=   3.2s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.15173764072442486, total=   3.3s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.16244624940277116, total=   3.5s\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.18101761252446183, total=   3.5s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.1718377088305489, total=   3.7s\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.15180722891566265, total=   3.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.1752336448598131, total=   3.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.17403574788334902, total=   3.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.16214908034849948, total=   3.7s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=25, score=0.15570065293822197, total=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.5374128091312619, total=   6.1s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.4670698924731182, total=   5.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.5603835780641295, total=   6.5s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.5777439024390243, total=   6.4s\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.46032291308828577, total=   6.5s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.49045865416806167, total=   6.6s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.4658815379286456, total=   6.3s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.4878048780487805, total=   6.4s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.5444170265268353, total=   6.5s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=50, score=0.4798598949211909, total=   6.3s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.6872381566226232, total=  11.7s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.7167315175097275, total=  11.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.7169900615238998, total=  11.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.695551128818061, total=  12.2s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.7093588336729895, total=  11.7s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   25.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.7044728434504792, total=  11.9s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.6935348446683459, total=  11.4s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.7099049371358479, total=  12.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.7042712748614279, total=  11.6s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=100, score=0.6953805687982904, total=  12.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7076780758556891, total=  22.7s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7342401638145385, total=  23.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7107250755287009, total=  23.5s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7363489972185624, total=  24.2s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   50.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7335482925399384, total=  23.1s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7235676314235084, total=  22.6s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7214996174445295, total=  23.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7263853000287108, total=  22.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.7259281617869, total=  23.3s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=200, score=0.715143328830857, total=  22.8s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7111882046834345, total=  44.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7488730551112404, total=  44.0s\n",
      "[CV] learning_rate=0.02, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7143886966551328, total=  43.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7426942266571633, total=  44.0s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5214424951267057, total=   5.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7399167503947179, total=  43.8s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.543042270904042, total=   5.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7345802398629355, total=  44.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5664794007490638, total=   5.5s\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5291338582677165, total=   5.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.525984251968504, total=   5.8s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5142405063291139, total=   5.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.541332510795805, total=   5.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5132396207911082, total=   5.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5065573770491805, total=   5.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7344750765803398, total=  43.3s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7277868730465843, total=  44.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=25, score=0.5251066622907777, total=   5.7s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.6839699640874959, total=  10.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.7174302951247351, total=  10.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.7056956739602471, total=  10.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.6965214564369311, total=  10.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.7063603688076262, total=  10.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.7034282018111254, total=  10.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.6948250846364662, total=  10.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.7082952119548643, total=  10.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.7087072116982386, total=  10.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=50, score=0.6997538966365874, total=  10.7s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7299912049252419, total=  42.1s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=2, n_estimators=400, score=0.7294525494727719, total=  42.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.6958925750394945, total=  20.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7271025120923702, total=  20.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.72611859420963, total=  20.3s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7101381042059006, total=  20.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7206174537673848, total=  20.3s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7149591451917033, total=  20.2s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7130351742798027, total=  20.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7197082465019351, total=  20.9s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7162076606521051, total=  20.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=100, score=0.7082603851663217, total=  20.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7479674796747968, total=  39.4s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7442942288123274, total=  39.3s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7244234180958014, total=  39.0s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  3.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7146064052678838, total=  40.2s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7427349166543736, total=  39.2s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.732608695652174, total=  39.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7325279094662793, total=  39.6s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7377049180327869, total=  39.5s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7312518673438902, total=  39.1s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=200, score=0.7299540536534755, total=  39.3s\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7571999448808048, total= 1.2min\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7214386459802539, total= 1.3min\n",
      "[CV] learning_rate=0.02, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.760229916518407, total= 1.3min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7298050139275766, total= 1.3min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7513566161124252, total= 1.3min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7437227074235809, total= 1.3min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5743449116392444, total=  12.3s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  4.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5931471350417505, total=  12.5s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5948007911839502, total=  12.5s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.6141114982578396, total=  12.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5875542691751086, total=  12.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5882352941176471, total=  11.8s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5739680626694788, total=  12.3s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.6020350480497456, total=  12.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5762358546754021, total=  12.2s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7442645074224022, total= 1.2min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=25, score=0.5899970050913447, total=  12.3s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7475154832205099, total= 1.3min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7218020388030254, total=  23.5s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7395523556112068, total=  24.0s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7460754167340994, total=  24.0s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7249190938511327, total=  24.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7296204107031737, total=  23.2s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  5.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7355926909261284, total=  23.5s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7346399777592438, total= 1.2min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=3, n_estimators=400, score=0.7406894642115465, total= 1.2min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7327658153897513, total=  23.9s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7429718875502008, total=  24.0s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7296209325729621, total=  24.0s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=50, score=0.7222131548881998, total=  23.9s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7255166217430368, total=  47.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7488730551112404, total=  47.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7547999413747618, total=  47.1s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7270857814336076, total=  47.5s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7454545454545454, total=  46.8s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7382116158711903, total=  46.7s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7398622800306044, total=  47.4s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7458250778375319, total=  47.2s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7302035358787698, total=  47.2s\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=100, score=0.7421289355322338, total=  47.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  7.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7321178120617112, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.758384668035592, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7588131210017693, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7315380344253193, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.756046993780235, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7464324917672888, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7515378443434073, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7529478619122034, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7423490488006618, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=200, score=0.7410210540800881, total= 1.5min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7278813336833815, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7668750797499043, total= 2.8min\n",
      "[CV] learning_rate=0.02, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7670708359923419, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7477678571428571, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7668353444920202, total= 2.8min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7620698510529018, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 11.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6294569391113549, total=  47.3s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6535031847133758, total=  48.0s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6452448820938067, total=  49.4s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6611461619348055, total=  49.7s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.759510686920285, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7564364007137395, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.650427571909821, total=  49.1s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6366459627329193, total=  50.0s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.635262449528937, total=  48.4s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6498708010335917, total=  48.3s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6219379422972238, total=  48.4s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=25, score=0.6299319727891156, total=  47.4s\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7525543620644486, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=5, n_estimators=400, score=0.7462587736723613, total= 2.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7272149888853605, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7497208486201946, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7514356029532403, total= 1.7min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7359201047806155, total= 1.7min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.751417004048583, total= 1.7min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 15.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7467022613065325, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7398873527905787, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7470055033991583, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7421479229989868, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=50, score=0.7312252964426879, total= 1.6min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.721248940378638, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7594673325010403, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7603074772886093, total= 3.4min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7346678023850086, total= 3.4min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7466063348416291, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.753678998762206, total= 3.4min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7465763510528641, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7568426873099254, total= 3.4min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7466322728575524, total= 3.4min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=100, score=0.7453550338470402, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7279392511128567, total= 6.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7583514655062077, total= 6.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7614442295293359, total= 6.8min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7412257726558408, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 26.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7579055178594291, total= 6.8min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7585359544749095, total= 6.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7464968152866243, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7511737089201879, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7487542617361657, total= 6.8min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=200, score=0.7481247532570074, total= 6.9min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7208977935582044, total=12.5min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7584094035263224, total=12.4min\n",
      "[CV] learning_rate=0.02, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7577081512919737, total=12.4min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.74128651973347, total=12.4min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7581658291457287, total=12.4min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7535780958307404, total=12.5min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6467941507311585, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6672811059907834, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.676432170181004, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6265432098765432, total= 3.2min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7495785241862275, total=12.6min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7445237509229633, total=12.5min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6566440349175556, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6535766961651918, total= 3.4min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6476582402508327, total= 3.2min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 47.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.671559633027523, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6519690974185037, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=25, score=0.6521739130434783, total= 3.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7442992569818089, total=12.5min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=10, n_estimators=400, score=0.7464897591137447, total=12.7min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.6628201519842386, total= 7.1min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.6903794986696542, total= 7.2min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.7034405906115058, total= 7.2min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.6857102751263336, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.6913869014859658, total= 7.1min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.701147835707371, total= 7.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.692039004511716, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.7086183310533516, total= 7.2min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.6954505940307159, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=50, score=0.6903225806451613, total= 7.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6915629322268326, total=15.7min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6665393430099313, total=16.1min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6822250639386189, total=15.6min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.7015996976949238, total=15.9min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6902545003103664, total=15.9min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6876558603491272, total=15.7min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 74.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.68391626576518, total=15.6min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6988650382432766, total=15.9min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6881897754661931, total=15.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=100, score=0.6894750587620789, total=16.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6940216729575063, total=33.7min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6643014436016638, total=34.5min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6758612081877183, total=34.5min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6970248937462052, total=35.1min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6896551724137931, total=33.6min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6827284864668043, total=35.2min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6938114655792756, total=34.3min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6857322438717788, total=34.9min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6851920009814747, total=34.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=200, score=0.6884333080232853, total=35.1min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.697786914983674, total=64.6min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6672276989660976, total=65.0min\n",
      "[CV] learning_rate=0.02, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6903364866483055, total=65.6min\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 175.4min\n",
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=25, score=0.0, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.17357762777242045, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.16244624940277116, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6851438492063492, total=65.5min\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.15180722891566265, total=   5.9s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.18101761252446183, total=   5.9s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.1718377088305489, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.1752336448598131, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.15173764072442486, total=   5.9s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.17403574788334902, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.16214908034849948, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=50, score=0.15570065293822197, total=   6.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.5374128091312619, total=  11.5s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.48408710217755446, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.5091339648173207, total=  11.3s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.46032291308828577, total=  11.5s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.49045865416806167, total=  11.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.4670698924731182, total=  11.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.5462705044877746, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.4878048780487805, total=  11.4s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 177.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.4537491240364401, total=  11.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=100, score=0.4798598949211909, total=  11.3s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.6851311953352769, total=  21.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.7167315175097275, total=  21.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.7169900615238998, total=  21.7s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.6967348284960423, total=  22.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.7093151984817333, total=  22.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.7041240409207162, total=  21.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.6950259588008708, total=  21.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.7099049371358479, total=  22.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.7042712748614279, total=  21.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=200, score=0.6945586059510109, total=  21.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7055026129726407, total=  42.8s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7338436625938465, total=  43.3s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7366885485047412, total=  43.1s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7103990326481257, total=  42.7s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7320299867705423, total=  42.7s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7243059657412876, total=  42.6s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7201107862748115, total=  43.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7260371959942775, total=  43.0s\n",
      "[CV] learning_rate=0.01, max_depth=2, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.7265601447090745, total=  43.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.01, max_depth=2, n_estimators=400, score=0.715143328830857, total=  43.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 182.9min\n",
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.2s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=25, score=0.0, total=   5.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5214424951267057, total=  10.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.543042270904042, total=  10.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.525984251968504, total=  10.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5664794007490638, total=  10.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5291338582677165, total=   9.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5142405063291139, total=  10.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5132396207911082, total=  10.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.541332510795805, total=   9.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6972665699080793, total=62.8min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5065573770491805, total=  10.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50, score=0.5251066622907777, total=  10.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.6839699640874959, total=  21.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.7174302951247351, total=  20.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.7056956739602471, total=  21.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.695859872611465, total=  20.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.7109613224201573, total=  20.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.7034282018111254, total=  20.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.6948250846364662, total=  20.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 185.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.709366391184573, total=  20.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.7087072116982386, total=  20.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.681682755333095, total=64.4min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100, score=0.6935817805383022, total=  20.2s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.6962425007893905, total=  40.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7275565964090552, total=  40.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7264428284078601, total=  41.2s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7088846880907373, total=  40.2s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7181942544459644, total=  40.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7150723725613592, total=  39.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7149673930332431, total=  40.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7189835575485799, total=  39.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7082603851663217, total=  38.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200, score=0.7204062202475404, total=  41.2s\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7128935532233883, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7470753739078929, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7440174039158809, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7238010657193605, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7427349166543736, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7330336426914154, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=3, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7332412946770976, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7377049180327869, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  11.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 190.4min\n",
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  11.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7312518673438902, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=400, score=0.7281696362833161, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  11.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=25, score=0.0, total=  12.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5768063145112324, total=  23.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5931471350417505, total=  23.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5948007911839502, total=  23.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.6133720930232558, total=  23.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5875542691751086, total=  23.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5882352941176471, total=  23.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5739680626694788, total=  23.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.6020350480497456, total=  22.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.5754323196183662, total=  23.1s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50, score=0.584019518145776, total=  23.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7241379310344829, total=  47.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7410896530067513, total=  46.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7437407952871871, total=  45.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7256493506493505, total=  46.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7373959478561332, total=  47.3s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7317073170731707, total=  46.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.734143499250874, total=  48.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7429718875502008, total=  48.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7212396560116826, total=  45.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.7309357309357308, total=  47.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 194.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7261940522679483, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7519345889910937, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7540083778708652, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7275132275132274, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7467579775608336, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7392241379310345, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7455395072217501, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7382962394474292, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7421052631578948, total= 1.5min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.7309463675531125, total= 1.5min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7593123209169054, total= 3.0min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7318271119842829, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7323513062812674, total= 3.0min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7593473827328348, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7546777546777546, total= 3.0min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7466996699669967, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7524660090642497, total= 3.0min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.688659540484089, total=64.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7528105877330297, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6918201387227935, total=64.5min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  47.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  48.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  48.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  47.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  50.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  45.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  50.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  45.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7416367155100912, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 206.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=400, score=0.7413010590015129, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  46.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=25, score=0.0, total=  47.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6267179769103903, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6541104606770173, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.644576753818276, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6611461619348055, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6503749676752004, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6360103626943006, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6359471840474266, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6491002570694087, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6226158038147139, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50, score=0.6292563334241351, total= 1.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7288676236044657, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7474763659669924, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7534246575342465, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7375573018991488, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7497969130787977, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7471715901948461, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.741216795201371, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7474813129671757, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7405836443841195, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.7344584122610641, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7228400342172797, total= 6.5min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7586494372655272, total= 6.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7604297474536068, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7381221719457013, total= 6.8min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7534152062922589, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.746458923512748, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 222.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7448517598948444, total= 6.8min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7573874620270644, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7489239598278334, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.7463336721359083, total= 6.8min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7566841499296406, total=13.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7270708126469819, total=13.8min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6833353562325526, total=63.9min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.02, max_depth=20, n_estimators=400, score=0.6958634438076251, total=65.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7612210580778683, total=13.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7388157894736842, total=14.0min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7567257427004972, total=13.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7604759441282981, total=13.9min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=25 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.0min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thi/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=25, score=0.0, total= 3.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7481612985036774, total=14.0min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7515727479587739, total=14.1min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.745740498034076, total=13.8min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=400, score=0.7494392400052777, total=13.9min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6481828400149868, total= 6.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.667595171773445, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=50 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6760037348272642, total= 6.5min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6265611990008326, total= 6.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6561576354679804, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 257.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6543255131964809, total= 6.8min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6500881143528491, total= 6.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6729006233956728, total= 6.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.6465350367789393, total= 6.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50, score=0.651558073654391, total= 6.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.6622844218264066, total=14.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.692318494593456, total=14.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.6829164297896532, total=14.1min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.7037505267593763, total=14.3min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.7036573494646086, total=14.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.6898225180255131, total=14.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.6933294409575245, total=13.9min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.7110717207526588, total=14.3min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.6915517747139924, total=14.0min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.6840742339231765, total=14.0min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6925312776443827, total=31.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6630185797912955, total=32.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.7066649930965232, total=31.8min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6846153846153846, total=31.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6971301884468531, total=31.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6920762286860581, total=31.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6901860166773572, total=31.3min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.7052080737602792, total=31.5min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6885768985322271, total=30.5min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.6928814446479981, total=32.6min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6938850238008056, total=67.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6631901840490798, total=69.4min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=400 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.7004009233385979, total=70.3min\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7140864714086471, total=   2.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7455241219078856, total=   2.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7476444080294963, total=   2.6s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 377.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7176308539944903, total=   2.9s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7397016559463528, total=   2.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7328539823008848, total=   2.6s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7314487632508834, total=   2.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6789970208540218, total=69.6min\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7397350993377483, total=   2.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7300639066407335, total=   2.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=25, score=0.7289746135299958, total=   2.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7263742215001353, total=   5.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7631265705594498, total=   5.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7650452340369739, total=   5.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7374392220421393, total=   5.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7516769696172563, total=   5.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7501320655044902, total=   5.2s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7480369196859071, total=   5.2s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7464607464607466, total=   5.3s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7456492637215529, total=   4.9s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=50, score=0.7376271186440678, total=   5.3s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7327473104172133, total=   9.9s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7695267410542518, total=   9.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7685456164906477, total=   9.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7416489925768823, total=  10.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7556855100714749, total=   9.6s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7570332480818414, total=  10.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7492987845599038, total=   9.6s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7489264965900481, total=   9.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7518944342827281, total=   9.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=100, score=0.7441460510649558, total=  10.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7368216047779798, total=  19.3s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7686971875394123, total=  19.4s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7715077465675777, total=  18.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7454308093994778, total=  19.3s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7635996465985107, total=  18.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 380.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7615894039735099, total=  19.0s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7529922399053005, total=  18.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7518003476533399, total=  18.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7517482517482518, total=  18.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=200, score=0.7491814014407335, total=  19.3s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.734314980793854, total=  37.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7718879537746514, total=  37.5s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7665050354345393, total=  37.8s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7390463917525772, total=  37.5s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7542319749216301, total=  37.6s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.762937595129376, total=  37.7s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7484055707405961, total=  37.5s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7487059403500124, total=  38.1s\n",
      "[CV] learning_rate=0.5, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7467366265676991, total=  37.3s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=2, n_estimators=400, score=0.7524303305249513, total=  38.4s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7233811975074506, total=   4.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7587113740959895, total=   4.5s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7659987071751777, total=   4.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.729223248234655, total=   4.7s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7588398887564561, total=   4.5s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7544224765868888, total=   4.7s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7427757427757428, total=   4.7s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7521378595491058, total=   4.6s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7458344353345676, total=   4.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6821184099915938, total=68.7min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=25, score=0.7397444519166106, total=   4.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7341322096391888, total=   8.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7681365576102419, total=   8.7s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.771932064870387, total=   8.6s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6902622632345798, total=68.3min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7429797191887675, total=   8.5s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7599641163655004, total=   8.9s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7614213197969543, total=   8.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=50 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 384.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7537183438295592, total=   8.7s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7519506670022653, total=   8.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7498062516145699, total=   9.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50, score=0.7461508093170154, total=   8.6s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7329265125941313, total=  16.6s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7742219982361095, total=  16.5s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7736063708759955, total=  16.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7449297971918878, total=  17.2s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7566746805010756, total=  16.0s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7631909547738693, total=  17.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7526100171798599, total=  16.3s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.749311983987991, total=  16.9s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7537752751471717, total=  16.6s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100, score=0.7468502402909469, total=  16.2s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7255400254129606, total=  31.9s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7717620762448776, total=  33.6s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7341269841269841, total=  31.3s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7660636306924516, total=  33.3s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7464647728694782, total=  32.9s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.759391992090954, total=  33.7s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7486665799401587, total=  33.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7460024600246004, total=  32.5s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.7462496821764557, total=  33.1s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200, score=0.749332655395958, total=  33.8s\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7257861635220125, total= 1.0min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7544072948328268, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7588227958598329, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7325404858299596, total= 1.0min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7421826721048078, total= 1.0min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7503669275929549, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7421221864951768, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7399020807833537, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7286044718581343, total=  10.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7643470683430849, total=  10.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7612935699005914, total=  10.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed: 389.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7456253216675244, total=  10.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7610454262601121, total=  10.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7506218905472636, total=  10.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7341518416436983, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7552117477382982, total=  10.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.7499374530898173, total=  10.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.742137560726157, total=   9.9s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=400, score=0.7438542860782068, total= 1.1min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=25, score=0.74059812604287, total=  10.6s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.721996443992888, total=  18.8s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7650239646061202, total=  19.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7342569269521411, total=  18.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7540417129458226, total=  19.3s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7508342602892102, total=  19.7s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7441348973607038, total=  18.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7476515249002702, total=  18.7s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7484548825710755, total=  19.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7429693438054218, total=  18.4s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50, score=0.7386724203579134, total=  18.7s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7161555721765145, total=  36.7s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.760241112067905, total=  37.1s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7472473091673884, total=  36.2s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7288557213930348, total=  36.6s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7365233192004845, total=  35.5s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7456896551724138, total=  37.0s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7410246582343172, total=  35.6s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7453874538745388, total=  37.3s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7285642444053307, total=  35.3s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100, score=0.7330276397911094, total=  37.8s\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7028337061894109, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7479792496079142, total= 1.2min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7238457760314342, total= 1.2min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7308301840789955, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7216251328687847, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7363013698630136, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=200 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 394.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7260221627818111, total= 1.2min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7355063747895118, total= 1.2min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.7253048021895993, total= 1.2min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200, score=0.721965245655707, total= 1.3min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7365182772348895, total= 2.6min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.687576126674787, total= 2.7min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7170207509881423, total= 2.1min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7122456265619421, total= 2.6min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7264748902974159, total= 2.2min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7046939988116458, total= 2.6min\n",
      "[CV] learning_rate=0.5, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7152839537542879, total= 2.2min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7243544183842691, total= 2.5min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.6904818988252218, total=  45.3s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7360282478996711, total=  43.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7235203415964891, total=  46.4s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7220708446866484, total= 2.1min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7053967471660917, total=  43.6s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=400, score=0.7079865855173268, total= 2.4min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.713020894817613, total=  47.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7305194805194806, total=  44.5s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7155161806324597, total=  45.0s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7235434007134364, total=  44.7s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7120608023922254, total=  46.4s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=25, score=0.7191653210781268, total=  46.1s\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6958202464363373, total=68.4min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.6743772241992881, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.6807716241443683, total=70.7min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.7128430557205655, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.7090651892019333, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.6937652811735942, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.6964596633778293, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.7134292565947243, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.7012458369310473, total= 1.5min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.7162290040217647, total= 1.5min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.6962490806570237, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50, score=0.701321150759353, total= 1.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6654592194437953, total= 3.4min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed: 409.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.7068282731309252, total= 3.1min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6812137330754352, total= 3.0min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6943965021286388, total= 3.3min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6917832373339603, total= 3.1min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.7032357109116675, total= 3.1min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6891084278570556, total= 3.4min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.701795290277454, total= 3.2min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6853004548719176, total= 3.2min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100, score=0.6873708520724443, total= 3.0min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.7022238078249495, total= 5.9min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6649251959154595, total= 7.3min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6768585131894485, total= 5.2min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6855264702429863, total= 5.9min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.684796474544822, total= 6.3min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6959008579599619, total= 6.4min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.68645413460364, total= 7.1min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6934475573049317, total= 6.3min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6772403811361717, total= 5.6min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200, score=0.6819821987009862, total= 6.4min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6948835031026812, total=11.0min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.666784786203638, total=12.9min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6737588652482269, total= 9.2min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6781036281441984, total=11.7min\n",
      "[CV] learning_rate=0.5, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6789184127355729, total=10.7min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6947058823529413, total=12.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6620250177012037, total= 4.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6948929553881114, total= 4.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.688321257521798, total=67.9min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.682232761765779, total=12.8min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6845481049562683, total= 4.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6887340301974448, total=12.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6781691828420799, total=12.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=400, score=0.687293938625412, total=71.5min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6873493975903614, total= 4.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6777196044211751, total= 4.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=400, score=0.6687402799377916, total=11.7min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.691975012013455, total= 4.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed: 447.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6807773239262285, total= 4.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6935635424007517, total= 4.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6836477231767393, total= 4.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=25, score=0.6761158021712907, total= 4.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6655188791260983, total= 6.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6954820348630382, total= 6.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6905949205612896, total= 6.5min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6857930043124102, total= 6.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6838551972994995, total= 6.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6933174224343676, total= 6.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6819015031162166, total= 6.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6963067513526229, total= 6.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6752701080432173, total= 6.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50, score=0.6828193832599119, total= 6.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6641086186540733, total= 9.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6943623685143601, total= 9.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.689396561670705, total= 9.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.688604873387482, total= 9.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.683491062039958, total= 9.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6915274463007159, total= 9.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6869049091133919, total= 9.0min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6903642773207991, total= 9.2min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6810035842293907, total= 9.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100, score=0.6746547042852085, total= 9.3min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6688726069487118, total=15.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.691838929382244, total=15.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6869434485948884, total=15.5min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6823613766730402, total=15.4min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6788679686586365, total=15.0min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.693127962085308, total=15.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6841267898666015, total=14.8min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6944769482798971, total=15.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6862862622872213, total=14.8min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200, score=0.6832958978602673, total=15.0min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.665611072015013, total=26.8min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6888517146612498, total=27.1min\n",
      "[CV] learning_rate=0.5, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6878980891719745, total=27.5min\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.6934959349593496, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7214841960604673, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed: 509.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7232320146632044, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.704169318905156, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7097961060861566, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7110307982401005, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7040065412919051, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.717964253256589, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7165354330708662, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=25, score=0.7055902610924235, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.7145056975669849, total=   5.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.737184222189393, total=   5.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.740577797330987, total=   5.7s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.715352449223417, total=   5.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6810057197330792, total=27.3min\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.7347118345798505, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.729905437352246, total=   5.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.7214080676839402, total=   5.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.731341149556763, total=   5.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.7298277425203988, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=50, score=0.7254278358321974, total=   5.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7160369195269687, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7511637748624629, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7469024084644299, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7211263579188107, total=  10.2s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7413914265635979, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7346737907761529, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7371186688074735, total=  10.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7406138668128255, total=  10.3s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.7303211139528276, total=  10.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=100, score=0.732961851693099, total=  10.2s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.719707424786089, total=  19.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7610020311442112, total=  19.7s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7585513078470825, total=  19.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7284858387799564, total=  19.8s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.748739610301131, total=  19.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7434596903363587, total=  19.8s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.74475573701253, total=  19.5s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7435090479937058, total=  19.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6765081948157619, total=26.9min\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7360544217687074, total=  19.6s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 513.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=200, score=0.7400796375120143, total=  20.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7306455933565497, total=  38.4s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7690802348336595, total=  37.9s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7676321600207819, total=  39.0s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6978271251193887, total=27.2min\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7386062533121356, total=  38.7s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7569198478289387, total=  38.6s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7580477673935618, total=  39.1s\n",
      "[CV] learning_rate=0.1, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7517316311286161, total=  39.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7527500639549758, total=  39.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7484872401999474, total=  38.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7086011631466176, total=   5.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7355880092236741, total=   5.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7428529106798993, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7196275946275946, total=   5.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.736392742796158, total=   5.2s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=2, n_estimators=400, score=0.7472880674969867, total=  38.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7282282282282283, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7203194593764398, total=   5.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.731991834354039, total=   5.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7294531011304612, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=25, score=0.7188989697062894, total=   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7171952283968577, total=   9.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.746470839868815, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7426439532591862, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7200929152148664, total=   9.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7418249321719264, total=  10.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7332955832389582, total=  10.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7328154770628755, total=   9.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7368348497380754, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7309899569583931, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50, score=0.7336917041987505, total=  10.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7226187208344771, total=  18.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7577187542132937, total=  18.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7637690776376909, total=  18.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7368995633187774, total=  18.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7551269862827651, total=  18.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7476012793176972, total=  18.2s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7446947864815301, total=  18.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7450678606408283, total=  18.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7387131657204649, total=  18.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed: 516.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100, score=0.7409925220938137, total=  18.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7670343932511355, total=  33.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7259984131182228, total=  35.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7694776023616995, total=  33.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7392331932773109, total=  34.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7620721072497723, total=  33.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7596899224806201, total=  34.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7518443997317237, total=  34.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7500638895987732, total=  35.2s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.749804228660924, total=  34.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200, score=0.7429292258664189, total=  33.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7303883242116237, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7709251101321586, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7717653022430617, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7440010432968179, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6851329819830861, total=26.5min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7651177593889242, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7621642169285353, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7288908502500735, total=  12.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7521949941030011, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7533299824076402, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.752741774675972, total=  12.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7575110351701553, total=  12.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7303695150115473, total=  12.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7492420961455175, total=  12.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7388635065676757, total=  12.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7425742574257426, total=  12.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7490924322814857, total=  11.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7349255491670352, total=  12.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=25, score=0.7421083116130901, total=  12.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7503217503217503, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=400, score=0.7511490479317138, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7281224600379301, total=  22.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6935031549427436, total=27.6min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7699431141685407, total=  23.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7571940060999868, total=  23.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7360064585575888, total=  23.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.76091363697797, total=  22.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7525239107332625, total=  22.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.756794425087108, total=  23.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7538642913282684, total=  22.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7430424209673061, total=  22.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 522.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50, score=0.7438909140002701, total=  23.3s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7301690507152145, total=  41.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7728706624605677, total=  42.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7683587353570978, total=  41.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7661856723279274, total=  41.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7636063072227873, total=  40.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7429979253112033, total=  43.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7553909247254927, total=  42.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7574993698008571, total=  41.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7510950785879927, total=  40.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.7493061979648473, total=  42.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7309184993531695, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7686114207853338, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7709086376667081, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7458847736625515, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.765209724146618, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7600846613545816, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7574173310678343, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7598464206093634, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7487953335024093, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.7507410748807836, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7291402485417194, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7625660562861005, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7449109414758271, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7646037455041548, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7561671005330358, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.760251976284585, total= 2.3min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7206477732793523, total=  51.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7572131365509905, total=  52.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7534511675912786, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7561993616498895, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.761144377910845, total=  52.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7371621621621622, total=  52.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7492002559181062, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=400, score=0.7452711223203027, total= 2.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7543075101933446, total=  52.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.754, total=  51.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7492715415568197, total=  52.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7501984652024346, total=  52.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7444915834131655, total=  51.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=25, score=0.7470312068489369, total=  51.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7198042750450683, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed: 532.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7588777960318464, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7582610880763915, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7417440660474717, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7475752613679305, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7555499495459131, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.6868856389355071, total=26.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7500989576461276, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.745570252058897, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7439938000516662, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50, score=0.7484014093696986, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=400, score=0.678227818030645, total=26.6min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7140156289387447, total= 2.9min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7585483273669918, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7517070142768467, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7404468318886583, total= 2.9min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7392131979695431, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7522178413011336, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.74096829687884, total= 2.9min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7466237942122187, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7383912712509515, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.7467822097616924, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7081357624157724, total= 5.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.740214841338437, total= 5.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7465728047424972, total= 5.5min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7312153303076148, total= 5.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7351331630791682, total= 5.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7423208191126279, total= 5.5min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7361480764577789, total= 5.4min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7387593937078079, total= 5.6min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7361340271608072, total= 5.5min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.7163377466899825, total= 5.6min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.693201064601984, total=11.5min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7284117430291119, total=11.6min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7081362919849643, total=11.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7142857142857143, total=11.7min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7140289924523782, total=11.7min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.721908734052993, total=11.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.658982711099975, total= 4.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6890176260322938, total= 4.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7205134415112618, total=11.7min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7172622805909837, total=11.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6828528072837633, total= 4.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.7029800915048844, total= 4.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=25 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed: 560.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6875225171130058, total= 4.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6934350775193797, total= 4.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6747801707658977, total= 4.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6998293099244087, total= 4.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6857072510156347, total= 4.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=25, score=0.6884057971014492, total= 4.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7109948947827169, total=11.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=400, score=0.7045735475896169, total=12.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6922798115259151, total= 8.4min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6618177446501564, total= 8.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6899147014550928, total= 8.7min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.680377854836781, total= 8.4min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.7036158861885004, total= 8.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6856971153846153, total= 8.5min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6947444204463643, total= 8.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6863971968464522, total= 8.9min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6864891158944424, total= 8.5min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50, score=0.6845162919929275, total= 8.9min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6924924924924926, total=15.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6623422994525113, total=16.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.7051660952831305, total=16.5min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6946489936180658, total=16.9min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6760763847704898, total=15.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6957773512476009, total=16.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6908752327746742, total=16.5min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6914258418915692, total=16.3min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6879458348446379, total=16.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.6890985845542587, total=16.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6632531555132173, total=28.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6940289577599617, total=28.4min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.700058582308143, total=28.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6912050534499514, total=28.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6957040572792363, total=27.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6822715006453126, total=27.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.690519877675841, total=28.4min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6951393852751966, total=28.4min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6903030303030304, total=28.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.6879694765708836, total=28.3min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6663897460242107, total=39.0min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6960142772159428, total=39.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.693033381712627, total=39.4min\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7098200670936261, total=   2.9s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7411520805567895, total=   3.0s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6955563290404919, total=39.7min\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7365070177977139, total=   3.1s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 663.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7164179104477613, total=   2.8s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7365190705830776, total=   2.8s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7291666666666666, total=   2.9s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7186521544654838, total=   3.1s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7343614874603632, total=   2.9s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7285115303983228, total=   3.0s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=25, score=0.7213483146067415, total=   2.8s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7126469744766275, total=   5.2s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7519899455383326, total=   5.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.747469144362779, total=   5.4s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7177236693091732, total=   5.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7393819669817977, total=   5.2s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7402234636871509, total=   5.0s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.738448251043616, total=   5.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7334795722511653, total=   5.4s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.7313943541488452, total=   5.4s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=50, score=0.728739210414603, total=   5.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7206896551724138, total=  10.2s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7583478610701355, total=  10.0s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7600477516912056, total=  10.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7235054347826088, total=   9.5s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7491432488005484, total=  10.4s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.745345744680851, total=   9.8s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.749965117901493, total=  10.1s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7388001047943411, total=   9.7s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7364288615134696, total=   9.6s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=100, score=0.7406409911123081, total=  10.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7315284075753534, total=  18.6s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7696781698332689, total=  19.5s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7677902621722846, total=  18.7s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7401055408970977, total=  19.6s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7605671127600371, total=  18.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7586518595041323, total=  19.6s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7526736158115609, total=  19.1s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7477707006369428, total=  19.6s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7490144546649146, total=  19.5s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=200, score=0.7465162574651626, total=  19.9s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7332201619221729, total=  37.8s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7746478873239436, total=  37.9s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7691821514347112, total=  36.4s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7433489827856026, total=  36.5s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7669105378000257, total=  36.0s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7601522842639594, total=  37.1s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7570957095709571, total=  36.3s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7493085240130752, total=  36.9s\n",
      "[CV] learning_rate=0.2, max_depth=2, n_estimators=400 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed: 669.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7541935483870967, total=  38.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.717065436725281, total=   5.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=2, n_estimators=400, score=0.7522065604004743, total=  38.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7477820025348542, total=   5.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7499650202882326, total=   5.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7225433526011561, total=   5.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7393519173623885, total=   5.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7343397291196389, total=   5.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.735101267667201, total=   5.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7366749516708093, total=   5.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7378950420411713, total=   4.9s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=25, score=0.7264651096145579, total=   5.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7213520197856554, total=   9.4s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7582049564634964, total=   9.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7609414253603067, total=   9.6s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7366071428571428, total=   9.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.757087196023109, total=   9.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7430444087747459, total=   9.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.751620466142601, total=   9.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7483702737940027, total=   9.4s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7415196743554952, total=   9.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=50, score=0.7356709372892783, total=   9.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7221631676853574, total=  17.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.768089771701277, total=  17.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.763383160853456, total=  16.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7426199261992621, total=  16.5s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.682798833819242, total=38.8min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7599275643513128, total=  16.8s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.756291730868002, total=  17.4s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.7001431297709924, total=38.9min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7557436517533254, total=  18.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7503176620076238, total=  17.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7500653936698928, total=  17.4s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=100, score=0.7514259185568378, total=  16.8s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7297332297332296, total=  32.5s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7687476447682452, total=  33.8s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7700623171817371, total=  32.5s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7446946169772256, total=  32.6s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7652996039350964, total=  32.6s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7652284263959391, total=  33.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7579734873342959, total=  32.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7545522574208032, total=  32.2s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7476275968196974, total=  34.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=200, score=0.7513999218648261, total=  32.6s\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7322390356501667, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7698084866691702, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7711069418386491, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1089 tasks      | elapsed: 675.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7417864476386037, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7558650106636557, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7591067864271457, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=3, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7543903042295326, total= 1.0min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7521949941030011, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7271394294854706, total=  11.7s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7574159525379038, total=  11.9s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7672062113435979, total=  12.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7366310160427807, total=  11.6s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7475083056478405, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7581994423051388, total=  11.4s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=3, n_estimators=400, score=0.7449151444487628, total= 1.1min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7488050982474774, total=  11.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=25 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7594501718213058, total=  11.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7504509147127029, total=  11.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.7450821880894636, total=  11.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=25, score=0.744035584310554, total=  11.2s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7324143262045865, total=  20.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7668212003508333, total=  20.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7689408217112702, total=  20.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7477967858994297, total=  20.4s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7633151137663658, total=  20.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7590863200403838, total=  20.6s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=50 .................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7606544398997229, total=  20.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7524393294971229, total=  20.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7481328869430852, total=  20.8s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=50, score=0.7473656823208014, total=  20.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7295102765795484, total=  38.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.766950722489811, total=  37.3s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.771899392888118, total=  37.9s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7451678535096643, total=  36.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7619403915700212, total=  37.2s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7630597014925373, total=  37.2s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7572412001558644, total=  36.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7496924969249693, total=  37.1s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7458808618504436, total=  38.6s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=100, score=0.7507372740094883, total=  38.6s\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7223884318125157, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7622659977976263, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7385793172690763, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.762826007101751, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7513273243610322, total= 1.3min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7551571709233792, total= 1.3min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7536977491961415, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7456990550036346, total= 1.3min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7442361287053458, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=200, score=0.7430125205514101, total= 1.2min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 682.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7168795391935887, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7586416009702851, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7273976023976024, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7520650967821477, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6932387822472184, total=39.6min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6919801277501775, total=39.9min\n",
      "[CV] learning_rate=0.2, max_depth=5, n_estimators=400 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7348165965123271, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7530712530712532, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.744228432563791, total= 2.3min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7381527124888833, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7223505260456762, total=  51.0s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7544211714536561, total=  51.4s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7330072736393278, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.754752612363087, total=  50.6s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7382593159775396, total=  51.3s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7455976020981641, total=  50.3s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7484992496248125, total=  50.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=5, n_estimators=400, score=0.7394500063363325, total= 2.4min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7489160425699646, total=  50.7s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7463335819040517, total=  48.8s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7392996108949418, total=  50.7s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=25, score=0.7412922439466529, total=  50.1s\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7157182251190775, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7558068084060464, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7465341675867991, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7317839195979899, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.740339472733839, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7474099654662062, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7374215849443092, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7365800340053437, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7322914040836905, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=50, score=0.7337753410684688, total= 1.5min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7037267080745341, total= 2.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7359202043547014, total= 2.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7316332726168792, total= 2.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7142857142857143, total= 3.0min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7308377896613191, total= 2.8min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.738943488943489, total= 2.8min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7271418286537077, total= 2.8min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7237092477483191, total= 2.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7201672156067899, total= 2.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=100, score=0.7203229468903748, total= 2.8min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6889668521654972, total=39.6min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=400, score=0.6855270994639666, total=39.7min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.6927930114049987, total= 6.1min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7231179536913565, total= 6.0min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7081391179634277, total= 6.1min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7088075210291935, total= 6.1min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7175813501699855, total= 5.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1185 tasks      | elapsed: 703.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.711641791044776, total= 6.0min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7080474111041796, total= 6.0min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7132684547828151, total= 5.9min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.6987385604748949, total= 6.2min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=200, score=0.7008252247813769, total= 6.0min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.7084485037856028, total=13.0min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6821437097159226, total=13.2min\n",
      "[CV] learning_rate=0.2, max_depth=10, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6958547365906104, total=13.0min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6967513434294089, total=13.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6938080131594407, total=13.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.7067307692307693, total=13.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6995141397782485, total=12.0min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.7005202175455191, total=13.0min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6597812879708385, total= 4.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6931416737726885, total= 4.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.7026044821320412, total= 4.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6759443339960238, total= 4.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=25 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6842794240152328, total= 4.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6920184376516253, total= 4.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6854688083675757, total= 4.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6921708185053381, total= 4.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6953183991945633, total= 4.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=25, score=0.6828913912095895, total= 4.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6957306073361395, total=13.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=10, n_estimators=400, score=0.6946136972946625, total=13.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6630460730484603, total= 8.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6930872240318494, total= 8.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=50 ................\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6852667645619188, total= 8.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6932748191199146, total= 8.7min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6883842587088337, total= 8.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6962927756653992, total= 8.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6937156802928613, total= 8.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6960598148587704, total= 8.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6931000248200546, total= 8.8min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=50, score=0.6830469782530337, total= 8.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6691648822269808, total=14.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6889128094725511, total=14.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6932944606413993, total=14.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6833251473477406, total=14.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6838978015448602, total=14.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6966238706609607, total=14.3min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6905025187369458, total=14.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6960667461263409, total=14.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6862040033561069, total=14.1min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=100, score=0.6862026862026863, total=14.4min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6752701080432174, total=19.9min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6941613715381849, total=19.9min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6927885171894895, total=20.0min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6849563953488372, total=20.0min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 772.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6926253687315633, total=19.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6972182596291012, total=19.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6899082568807339, total=19.6min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6973152767878356, total=19.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6886082098615497, total=19.8min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=200, score=0.6860868524943176, total=19.7min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6720941288328975, total=30.5min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6948929553881114, total=31.2min\n",
      "[CV] learning_rate=0.2, max_depth=20, n_estimators=400 ...............\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6913850766924231, total=31.3min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6849808061420345, total=31.3min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.7014943074003795, total=28.9min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6891685287545573, total=29.1min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6897182583241859, total=26.8min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6920537609054468, total=26.9min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6900507123883121, total=20.0min\n",
      "[CV]  learning_rate=0.2, max_depth=20, n_estimators=400, score=0.6809222315135586, total=19.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1250 out of 1250 | elapsed: 823.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8630\n",
      "F-score on testing data: 0.7395\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8699\n",
      "Final F-score on the testing data: 0.7512\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = GradientBoostingClassifier(random_state=30)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {'learning_rate':[0.02, 0.01, 0.5, 0.1, 0.2],  # default=0.1\n",
    "              'n_estimators':[25,50,100,200,400],  # default=100\n",
    "              'max_depth':[2, 3, 5, 10, 20]} # default=3\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "cv = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 30)\n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, cv = cv, scoring=scorer, n_jobs=-1, verbose=10)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(grid_obj.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 - Final Model Evaluation\n",
    "\n",
    "* What is your optimized model's accuracy and F-score on the testing data? \n",
    "* Are these scores better or worse than the unoptimized model? \n",
    "* How do the results from your optimized model compare to the naive predictor benchmarks you found earlier in **Question 1**?_  \n",
    "\n",
    "**Note:** Fill in the table below with your results, and then provide discussion in the **Answer** box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "|     Metric     | Unoptimized Model | Optimized Model |\n",
    "| :------------: | :---------------: | :-------------: | \n",
    "| Accuracy Score |    0.8630         |       0.8699    |\n",
    "| F-score        |  0.7395           |    0.7512       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ** The optimized model's accuracy and F-score on the testing data are: 0.8699 and 0.7512, respectively. These scores are slightly higher than the unoptimized model (0.8630 and 0.7395, respectively). The performance of the optimized model outperforms significantly when compared to the naive predictor in Question 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Feature Importance\n",
    "\n",
    "An important task when performing supervised learning on a dataset like the census data we study here is determining which features provide the most predictive power. By focusing on the relationship between only a few crucial features and the target label we simplify our understanding of the phenomenon, which is most always a useful thing to do. In the case of this project, that means we wish to identify a small number of features that most strongly predict whether an individual makes at most or more than \\$50,000.\n",
    "\n",
    "Choose a scikit-learn classifier (e.g., adaboost, random forests) that has a `feature_importance_` attribute, which is a function that ranks the importance of features according to the chosen classifier.  In the next python cell fit this classifier to training set and use this attribute to determine the top 5 most important features for the census dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 - Feature Relevance Observation\n",
    "When **Exploring the Data**, it was shown there are thirteen available features for each individual on record in the census data. Of these thirteen records, which five features do you believe to be most important for prediction, and in what order would you rank them and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "2- **Age**: People aged from 30-60 are tended to earn more than youger (less experience or still studying) or older people (retired or part-time workers).\n",
    "\n",
    "2- **Occupation**: High skilled people like doctors or dentist (Prof-specialty) are paid more than lower skill employee like Handlers/clearners.\n",
    "\n",
    "3- **Workclass**: Working for the state or government does not always pay as much as working in the private sector.\n",
    "\n",
    "4- **Education Number**: People have longer education number are likely having a higher paid jobs than lower education people.\n",
    "\n",
    "5- **Hours per week**: Part-time workers are likely to earn less than full-time workers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Extracting Feature Importance\n",
    "Choose a `scikit-learn` supervised learning algorithm that has a `feature_importance_` attribute availble for it. This attribute is a function that ranks the importance of each feature when making predictions based on the chosen algorithm.\n",
    "\n",
    "In the code cell below, you will need to implement the following:\n",
    " - Import a supervised learning model from sklearn if it is different from the three used earlier.\n",
    " - Train the supervised model on the entire training set.\n",
    " - Extract the feature importances using `'.feature_importances_'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Import a supervised learning model that has 'feature_importances_'\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# TODO: Train the supervised model on the training set using .fit(X_train, y_train)\n",
    "model = GradientBoostingClassifier(n_estimators=400, learning_rate=0.2, max_depth=2, random_state=30)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Plot\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 - Extracting Feature Importance\n",
    "\n",
    "Observe the visualization created above which displays the five most relevant features for predicting if an individual makes at most or above \\$50,000.  \n",
    "* How do these five features compare to the five features you discussed in **Question 6**?\n",
    "* If you were close to the same answer, how does this visualization confirm your thoughts? \n",
    "* If you were not close, why do you think these features are more relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Age, hours-per-week and education number matched with my prediction. However, I did not expect the captial-gain and capital-loss are important features. I noticed that all five selected features are numerical features, it maybe because the process of converting one categorical variable into multiple numerical features through one-hot encoding. The multiple numerical features as the result play less important role compare to the orginal feature. Nonetheless, it was pretty close and the visualization confirms my thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "How does a model perform if we only use a subset of all the available features in the data? With less features required to train, the expectation is that training and prediction time is much lower â€” at the cost of performance metrics. From the visualization above, we see that the top five most important features contribute more than half of the importance of **all** features present in the data. This hints that we can attempt to *reduce the feature space* and simplify the information required for the model to learn. The code cell below will use the same optimized model you found earlier, and train it on the same training set *with only the top five important features*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model trained on full data\n",
      "------\n",
      "Accuracy on testing data: 0.8699\n",
      "F-score on testing data: 0.7512\n",
      "\n",
      "Final Model trained on reduced data\n",
      "------\n",
      "Accuracy on testing data: 0.8421\n",
      "F-score on testing data: 0.6986\n"
     ]
    }
   ],
   "source": [
    "# Import functionality for cloning a model\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 - Effects of Feature Selection\n",
    "\n",
    "* How does the final model's F-score and accuracy score on the reduced data using only five features compare to those same scores when all features are used?\n",
    "* If training time was a factor, would you consider using the reduced data as your training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** When using only five the most relevant features suggested from the Gradient Boosting Classifier, the model performs slightly worse (-0.0278 in accuracy score and -0.0526 in f-score) compare to using all features. However, reducing the number of features also reduces the tranining time. So if the training time is an important factor or the training set is too large, I would recommend to reduce the number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Before You Submit\n",
    "You will also need run the following in order to convert the Jupyter notebook into HTML, so that your submission will include both files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[NbConvertApp] Converting notebook finding_donors.ipynb to html',\n",
       " '[NbConvertApp] Writing 733259 bytes to finding_donors.html']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!jupyter nbconvert *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
